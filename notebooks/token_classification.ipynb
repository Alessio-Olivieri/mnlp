{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/notebooks/../src/paths.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import paths\n",
    "import dataset\n",
    "import train\n",
    "import utils\n",
    "import torch\n",
    "import pickle\n",
    "import evaluation\n",
    "\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7feacc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8fa9bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = paths.data/\"manzoni_train_tokens.csv\"\n",
    "OOD_DATA = paths.data/\"OOD_test.csv\"\n",
    "HF_DATA = paths.data/\"prepared\"\n",
    "torch.set_float32_matmul_precision(\"high\")   # enable TF32 matmuls on Ampere\n",
    "torch.backends.cudnn.allow_tf32 = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f383f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def check_labels(hfds_split, sample_rows=2000):\n",
    "    # Concatenate labels from a subset of rows (pad to same length already handled by collator)\n",
    "    n = min(sample_rows, len(hfds_split))\n",
    "    cats = []\n",
    "    for ex in hfds_split.select(range(n)):\n",
    "        labs = np.array(ex[\"labels\"])\n",
    "        cats.append(labs)\n",
    "    all_labs = np.concatenate(cats)\n",
    "    visible = all_labs[all_labs != -100]\n",
    "    uniq = np.unique(visible)\n",
    "    print(\"Unique visible labels:\", uniq)\n",
    "    bad = [x for x in uniq if x not in (0, 1)]\n",
    "    if bad:\n",
    "        print(\"❌ Found out-of-range labels:\", bad)\n",
    "    else:\n",
    "        print(\"✅ Labels look fine (only 0/1).\")\n",
    "    return uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12bed86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/deberta-v3-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862f3048891845709b6f47ec264d1b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed65fd03d4ef4cc89ebcf12a01905188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c49362de4347b780382766469d326e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b831eab13ad4280a43d03ecd9c45d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1564e78bc6341668ad53d18c4f11b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/298 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d67ca931b0492d9ad38d288e5da458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/238 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbfb4fd94264014944a37e4857b1b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique visible labels: [0 1]\n",
      "✅ Labels look fine (only 0/1).\n",
      "Unique visible labels: [0 1]\n",
      "✅ Labels look fine (only 0/1).\n",
      "\n",
      "=== Training deberta -> microsoft/deberta-v3-base ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43da05a8aecb4197829bcc5e79c42051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acccdbca839b4f97b972ae7ad762b1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/user/mnlp/notebooks/../src/train.py:104: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 00:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.972171</td>\n",
       "      <td>0.998266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>0.994526</td>\n",
       "      <td>0.988214</td>\n",
       "      <td>0.999249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.998165</td>\n",
       "      <td>0.992701</td>\n",
       "      <td>0.995425</td>\n",
       "      <td>0.999711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[deberta] Validation: {'eval_loss': 0.0014371608849614859, 'eval_precision': 0.998165137614679, 'eval_recall': 0.9927007299270073, 'eval_f1': 0.9954254345837146, 'eval_accuracy': 0.999711066165848, 'eval_runtime': 0.5406, 'eval_samples_per_second': 110.997, 'eval_steps_per_second': 14.8, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answerdotai/ModernBERT-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679f838fe2bf4d09839b0e478d248033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dee1ef9187c44b4bad07771fad326d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed87897ff31e45a6bd6f591548e38314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc60696c3130486dad720f3e4efb5da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5986c0fa75e94ce2a9373f3cec78b86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/67 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dde2caea8e4f42af084fb90d90aff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/53 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe10c94972a748e8b167f445ed8d7fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique visible labels: [0 1]\n",
      "✅ Labels look fine (only 0/1).\n",
      "Unique visible labels: [0 1]\n",
      "✅ Labels look fine (only 0/1).\n",
      "\n",
      "=== Training modernbert -> answerdotai/ModernBERT-base ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce19fce7ea6470f85f3bc4db54df8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694f4a300d5f4a4896a812d815b59c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/user/mnlp/notebooks/../src/train.py:104: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.066487</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.611842</td>\n",
       "      <td>0.714012</td>\n",
       "      <td>0.981938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.016981</td>\n",
       "      <td>0.949740</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.924895</td>\n",
       "      <td>0.994606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.960199</td>\n",
       "      <td>0.952303</td>\n",
       "      <td>0.956235</td>\n",
       "      <td>0.996788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modernbert] Validation: {'eval_loss': 0.008771635591983795, 'eval_precision': 0.9601990049751243, 'eval_recall': 0.9523026315789473, 'eval_f1': 0.9562345169281585, 'eval_accuracy': 0.9967876841020668, 'eval_runtime': 0.3818, 'eval_samples_per_second': 36.672, 'eval_steps_per_second': 5.239, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-multilingual-cased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05d0a3b7f6242d3b7390ed803edf5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cedea8cdf24d818b52c2e7a49a84e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87969234e18b4c86a4a94406d1513a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc42437f8b046289de38c7d478503cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20eadcb709fb47f29144e4593bc39d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd14919a9f97450c9813569c8c73e097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fdf2445bcf4bb085f62434f8f7245d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/211 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a2ed3677ee491494c5b725d7633551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/53 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique visible labels: [0 1]\n",
      "✅ Labels look fine (only 0/1).\n",
      "Unique visible labels: [0 1]\n",
      "✅ Labels look fine (only 0/1).\n",
      "\n",
      "=== Training bert -> bert-base-multilingual-cased ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c363d826b01a4207baf23123d8fb00c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/user/mnlp/notebooks/../src/train.py:104: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [81/81 00:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.016467</td>\n",
       "      <td>0.849635</td>\n",
       "      <td>0.996575</td>\n",
       "      <td>0.917258</td>\n",
       "      <td>0.993922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>0.949429</td>\n",
       "      <td>0.996575</td>\n",
       "      <td>0.972431</td>\n",
       "      <td>0.998090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>0.981356</td>\n",
       "      <td>0.991438</td>\n",
       "      <td>0.986371</td>\n",
       "      <td>0.999074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bert] Validation: {'eval_loss': 0.003856485243886709, 'eval_precision': 0.9813559322033898, 'eval_recall': 0.9914383561643836, 'eval_f1': 0.9863713798977853, 'eval_accuracy': 0.999073752460345, 'eval_runtime': 0.2376, 'eval_samples_per_second': 223.074, 'eval_steps_per_second': 29.463, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deberta': {'eval_loss': 0.0014371608849614859, 'eval_precision': 0.998165137614679, 'eval_recall': 0.9927007299270073, 'eval_f1': 0.9954254345837146, 'eval_accuracy': 0.999711066165848, 'eval_runtime': 0.5406, 'eval_samples_per_second': 110.997, 'eval_steps_per_second': 14.8, 'epoch': 3.0}, 'modernbert': {'eval_loss': 0.008771635591983795, 'eval_precision': 0.9601990049751243, 'eval_recall': 0.9523026315789473, 'eval_f1': 0.9562345169281585, 'eval_accuracy': 0.9967876841020668, 'eval_runtime': 0.3818, 'eval_samples_per_second': 36.672, 'eval_steps_per_second': 5.239, 'epoch': 3.0}, 'bert': {'eval_loss': 0.003856485243886709, 'eval_precision': 0.9813559322033898, 'eval_recall': 0.9914383561643836, 'eval_f1': 0.9863713798977853, 'eval_accuracy': 0.999073752460345, 'eval_runtime': 0.2376, 'eval_samples_per_second': 223.074, 'eval_steps_per_second': 29.463, 'epoch': 3.0}}\n"
     ]
    }
   ],
   "source": [
    "if train_flag:\n",
    "    import importlib\n",
    "    importlib.reload(dataset)\n",
    "    importlib.reload(train)\n",
    "\n",
    "    import os\n",
    "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # makes the exception point to the correct op\n",
    "\n",
    "    results = {}\n",
    "    for model_key in [\"deberta\", \"modernbert\", \"bert\"]:\n",
    "        pairs = dataset.read_token_label_file(TRAIN_DATA)\n",
    "        sents_tok, sents_lab = dataset.group_into_sentences(pairs)\n",
    "        ds_full = dataset.build_hf_dataset_for_token_classification(sents_tok, sents_lab, model_key=model_key)\n",
    "        split = ds_full.train_test_split(train_size=0.8, seed=69)\n",
    "        train_ds = dataset.tidy(split[\"train\"], model_key)\n",
    "        val_ds   = dataset.tidy(split[\"test\"], model_key)\n",
    "        train_ds.save_to_disk(HF_DATA/f\"{model_key}\"/\"train\")\n",
    "        val_ds.save_to_disk(HF_DATA/f\"{model_key}\"/\"val\")\n",
    "        _ = check_labels(train_ds)  # your ModernBERT train split\n",
    "        _ = check_labels(val_ds)\n",
    "        print(f\"\\n=== Training {model_key} -> {utils.MODEL_SPECS[model_key].name} ===\")\n",
    "        out_dir = str(paths.chekpoints / model_key)\n",
    "        results[model_key] = train.train_token_splitter(\n",
    "            train_ds, val_ds,\n",
    "            model_key=model_key, out_dir=out_dir,\n",
    "            lr=5e-5, batch_size=8, epochs=3,\n",
    "        )\n",
    "    with open(paths.results/\"token_class_eval.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "else:\n",
    "    with open(paths.results/\"token_class_eval.pkl\", \"rb\") as f:\n",
    "        results = pickle.load(f)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f14dfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deberta</th>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.998165</td>\n",
       "      <td>0.992701</td>\n",
       "      <td>0.995425</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.5406</td>\n",
       "      <td>110.997</td>\n",
       "      <td>14.800</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>0.003856</td>\n",
       "      <td>0.981356</td>\n",
       "      <td>0.991438</td>\n",
       "      <td>0.986371</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>0.2376</td>\n",
       "      <td>223.074</td>\n",
       "      <td>29.463</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modernbert</th>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.960199</td>\n",
       "      <td>0.952303</td>\n",
       "      <td>0.956235</td>\n",
       "      <td>0.996788</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>36.672</td>\n",
       "      <td>5.239</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            eval_loss  eval_precision  eval_recall   eval_f1  eval_accuracy  \\\n",
       "deberta      0.001437        0.998165     0.992701  0.995425       0.999711   \n",
       "bert         0.003856        0.981356     0.991438  0.986371       0.999074   \n",
       "modernbert   0.008772        0.960199     0.952303  0.956235       0.996788   \n",
       "\n",
       "            eval_runtime  eval_samples_per_second  eval_steps_per_second  \\\n",
       "deberta           0.5406                  110.997                 14.800   \n",
       "bert              0.2376                  223.074                 29.463   \n",
       "modernbert        0.3818                   36.672                  5.239   \n",
       "\n",
       "            epoch  \n",
       "deberta       3.0  \n",
       "bert          3.0  \n",
       "modernbert    3.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(results).T.sort_values(\"eval_f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4817667a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/notebooks/../src/evaluation.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Window 0 — predicted 6 sentences:\n",
      "▁a ▁cui ▁dove ▁tir ▁il ▁collo ▁\" ▁per ▁il ▁ban ▁di ▁dome ▁\" ▁e ▁port ▁; ▁per ▁non ▁bis ▁mai ▁and ▁con ▁le ▁mani ▁v ▁da ▁que ▁sign ▁. | ▁Rac ▁tutto ▁l ▁acc ▁; ▁e ▁ved ▁che ▁vi ▁di ▁\" ▁su ▁due ▁pie ▁\" ▁di ▁quell ▁co ▁che ▁a ▁no ▁non ▁ver ▁in ▁test ▁\" ▁a ▁pens ▁un ▁an ▁. ▁» | ▁Renzo ▁ab ▁molto ▁vol ▁questo ▁pare ▁; ▁Lucia ▁l ▁app ▁; ▁e ▁Agnes ▁\" ▁superb ▁d ▁a ▁da ▁\" ▁lev ▁\" ▁a ▁una ▁a ▁una ▁\" ▁le ▁po ▁best ▁dalla ▁st ▁\" ▁ri ▁le ▁loro ▁ ▁gamb ▁\" ▁come ▁se ▁faces ▁un ▁m ▁di ▁fi ▁\" ▁le ▁av ▁e ▁le ▁st ▁con ▁uno ▁spa ▁\" ▁e ▁le ▁cons ▁in ▁man ▁a ▁Renzo ▁; ▁il ▁qual ▁\" ▁date ▁e ▁rice ▁parole ▁di ▁s ▁\" ▁us ▁dalla ▁parte ▁dell ▁or ▁\" ▁per ▁non ▁ ▁ved ▁da ▁rag ▁\" ▁che ▁gli ▁corre ▁diet ▁\" ▁grid ▁: ▁lo ▁spo ▁! ▁lo ▁spo ▁! | ▁Co ▁\" ▁at ▁i ▁camp ▁o ▁\" ▁come ▁di ▁col ▁\" ▁i ▁lu ▁\" ▁se ▁n ▁and ▁per ▁vi ▁\" ▁fre ▁\" ▁ripen ▁all ▁sua ▁dis ▁\" ▁e ▁rum ▁il ▁disc ▁da ▁fare ▁al ▁do ▁Azz ▁. | ▁Las ▁poi ▁pens ▁al ▁let ▁\" ▁come ▁doves ▁stare ▁in ▁via ▁quell ▁po ▁best ▁\" ▁cos ▁leg ▁e ▁ten ▁per ▁le ▁za ▁\" ▁a ▁capo ▁all ▁in ▁gi ▁\" ▁nella ▁man ▁d ▁un ▁u ▁il ▁qual ▁\" ▁a ▁da ▁t ▁passion ▁\" ▁accom ▁col ▁gest ▁i ▁pens ▁che ▁gli ▁pass ▁a ▁tumult ▁per ▁la ▁men ▁. | ▁Ora ▁st ▁il ▁bra ▁per ▁colle ▁\" ▁or ▁l ▁a ▁per ▁dis ▁\" ▁or ▁lo ▁di ▁in ▁a ▁\"\n",
      "\n",
      "Window 1 — predicted 18 sentences:\n",
      "▁più ▁aff ▁\" ▁Feder ▁: ▁« ▁voi ▁a ▁una ▁bu ▁nu ▁da ▁dar ▁\" ▁e ▁me ▁la ▁fate ▁tanto ▁so ▁? ▁» | ▁« ▁Una ▁bu ▁nu ▁\" ▁io ▁? | ▁Ho ▁l ▁inferno ▁nel ▁cu ▁; ▁e ▁vi ▁dar ▁una ▁bu ▁nu ▁? | ▁Dit ▁voi ▁\" ▁se ▁lo ▁sap ▁\" ▁qual ▁è ▁quest ▁bu ▁nu ▁che ▁as ▁da ▁un ▁par ▁mio ▁. ▁» | ▁« ▁Che ▁Dio ▁v ▁ha ▁to ▁il ▁cu ▁\" ▁e ▁vu ▁far ▁suo ▁\" ▁» ▁ris ▁pa ▁il ▁cardinal ▁. | ▁« ▁Dio ▁! ▁Dio ▁! ▁Dio ▁! | ▁Se ▁lo ▁ved ▁! | ▁Se ▁lo ▁sent ▁! | ▁Dov ▁è ▁questo ▁Dio ▁? ▁» | ▁« ▁Voi ▁me ▁lo ▁do ▁? ▁voi ▁? | ▁E ▁chi ▁più ▁di ▁voi ▁l ▁ha ▁vic ▁? | ▁Non ▁ve ▁lo ▁sent ▁in ▁cu ▁\" ▁che ▁v ▁op ▁\" ▁che ▁v ▁a ▁\" ▁che ▁non ▁vi ▁las ▁stare ▁\" ▁e ▁n ▁st ▁tempo ▁v ▁at ▁\" ▁vi ▁fa ▁present ▁una ▁s ▁di ▁quiet ▁\" ▁di ▁cons ▁\" ▁d ▁una ▁cons ▁che ▁sar ▁pie ▁\" ▁i ▁\" ▁sub ▁che ▁voi ▁lo ▁rico ▁\" ▁lo ▁confess ▁\" ▁l ▁impl ▁? ▁» | ▁« ▁Oh ▁\" ▁cer ▁! ▁ho ▁qui ▁qual ▁cosa ▁che ▁m ▁op ▁\" ▁che ▁mi ▁rode ▁! | ▁Ma ▁Dio ▁! | ▁Se ▁c ▁è ▁questo ▁Dio ▁\" ▁se ▁è ▁quell ▁che ▁di ▁\" ▁cosa ▁vol ▁che ▁f ▁di ▁me ▁? ▁» | ▁Quest ▁parole ▁fur ▁de ▁con ▁un ▁accent ▁disp ▁; ▁ma ▁Feder ▁\" ▁con ▁un ▁to ▁sole ▁\" ▁come ▁di ▁placid ▁is ▁\" ▁ris ▁: ▁« ▁cosa ▁pu ▁far ▁Dio ▁di ▁voi ▁? ▁cosa ▁vu ▁far ▁? | ▁Un ▁seg ▁della ▁sua ▁pot ▁e ▁della ▁sua ▁bon ▁: ▁vu ▁ca ▁da ▁voi ▁una ▁glo ▁che ▁ness ▁al ▁gli ▁pot ▁dare ▁. | ▁Che ▁il ▁mondo ▁grid ▁da ▁tanto ▁tempo ▁contro ▁di ▁voi ▁\" ▁che ▁mill ▁e ▁mill ▁voc ▁detest ▁le ▁vos ▁op ▁. ▁» ▁( ▁l ▁in ▁si ▁sc ▁\" ▁e ▁rim ▁stu ▁un ▁momento ▁nel ▁sent ▁quel ▁lingua ▁cos ▁in ▁\"\n",
      "\n",
      "Window 2 — predicted 19 sentences:\n",
      "▁i ▁servi ▁delle ▁due ▁part ▁si ▁sl ▁all ▁dif ▁de ▁loro ▁pad ▁. | ▁Il ▁combat ▁era ▁dis ▁\" ▁e ▁per ▁il ▁numero ▁\" ▁e ▁anche ▁per ▁Lod ▁mi ▁pi ▁a ▁scans ▁i ▁col ▁\" ▁e ▁a ▁disarm ▁il ▁ne ▁\" ▁che ▁ad ▁ ▁; ▁ma ▁questo ▁vol ▁la ▁mort ▁di ▁lui ▁\" ▁a ▁ogni ▁cost ▁. | ▁Lod ▁a ▁gi ▁rice ▁al ▁bra ▁sin ▁una ▁pug ▁d ▁un ▁bravo ▁\" ▁e ▁una ▁s ▁leg ▁in ▁una ▁guan ▁\" ▁e ▁il ▁ne ▁principal ▁gli ▁pi ▁add ▁per ▁fin ▁; ▁quando ▁Cristo ▁\" ▁ved ▁il ▁suo ▁pad ▁ne ▁est ▁per ▁\" ▁and ▁col ▁pug ▁add ▁al ▁sign ▁. | ▁Quest ▁\" ▁riv ▁t ▁la ▁sua ▁i ▁contro ▁di ▁lui ▁\" ▁lo ▁pass ▁con ▁la ▁spa ▁. | ▁A ▁quell ▁vista ▁\" ▁Lod ▁\" ▁come ▁fu ▁di ▁sé ▁\" ▁c ▁la ▁sua ▁nel ▁vent ▁del ▁fer ▁\" ▁il ▁qual ▁cad ▁mori ▁\" ▁quasi ▁a ▁un ▁punto ▁col ▁pov ▁Cristo ▁. | ▁I ▁bra ▁del ▁gent ▁\" ▁visto ▁ch ▁era ▁fin ▁\" ▁si ▁died ▁all ▁fug ▁\" ▁mal ▁: ▁quell ▁di ▁Lod ▁\" ▁tart ▁e ▁sf ▁anche ▁loro ▁\" ▁non ▁essen ▁più ▁a ▁chi ▁dare ▁\" ▁e ▁non ▁vol ▁trova ▁imp ▁nella ▁gente ▁\" ▁che ▁gi ▁acc ▁\" ▁scan ▁da ▁al ▁parte ▁: ▁e ▁Lod ▁si ▁t ▁solo ▁\" ▁con ▁que ▁due ▁fun ▁comp ▁a ▁pie ▁\" ▁in ▁mezzo ▁a ▁una ▁foll ▁. | ▁« ▁Com ▁è ▁and ▁? | ▁– ▁ ▁uno ▁. | ▁– ▁Son ▁due ▁. | ▁– ▁Gli ▁ha ▁fat ▁un ▁ ▁nel ▁vent ▁. | ▁– ▁Chi ▁è ▁stato ▁a ▁? | ▁– ▁Quel ▁pre ▁. | ▁– ▁Oh ▁santa ▁Maria ▁\" ▁che ▁s ▁! | ▁– ▁Chi ▁cerca ▁trova ▁. | ▁– ▁Una ▁le ▁p ▁tutte ▁. | ▁– ▁Ha ▁fin ▁anche ▁lui ▁. | ▁– ▁Che ▁col ▁! | ▁– ▁Vu ▁essere ▁una ▁fac ▁s ▁. | ▁– ▁E ▁quell\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 0 — 6 predicted sentences:\n",
      " • a cui dove tir il collo \" per il ban di dome \" e port ; per non bis mai and con le mani v da que sign .\n",
      " • Rac tutto l acc ; e ved che vi di \" su due pie \" di quell co che a no non ver in test \" a pens un an . »\n",
      " • Renzo ab molto vol questo pare ; Lucia l app ; e Agnes \" superb d a da \" lev \" a una a una \" le po best dalla st \" ri le loro gamb \" come se faces un m di fi \" le av e le st con uno spa \" e le cons in man a Renzo ; il qual \" date e rice parole di s \" us dalla parte dell or \" per non ved da rag \" che gli corre diet \" grid : lo spo ! lo spo ! Co \"\n",
      " • at i camp o \" come di col \" i lu \" se n and per vi \" fre \" ripen all sua dis \" e rum il disc da fare al do Azz . Las poi\n",
      " • pens al let \" come doves stare in via quell po best \" cos leg e ten per le za \" a capo all in gi \" nella man d un u il qual \" a da t passion \" accom col gest i pens che gli pass a tumult per la men . Ora st\n",
      " • il bra per colle \" or l a per dis \" or lo di in a \"\n",
      "\n",
      "Example 1 — 18 predicted sentences:\n",
      " • più aff \" Feder : « voi a una bu nu da dar \" e me la fate tanto so ? »\n",
      " • « Una bu nu \" io ?\n",
      " • Ho l inferno nel cu ; e vi dar una bu nu ?\n",
      " • Dit voi \" se lo sap \" qual è quest bu nu che as da un par mio . »\n",
      " • « Che Dio v ha to il cu \" e vu far suo \" » ris pa il cardinal .\n",
      " • « Dio ! Dio ! Dio !\n",
      " • Se lo ved !\n",
      " • Se lo sent !\n",
      " • Dov è questo Dio ? »\n",
      " • « Voi me lo do ? voi ?\n",
      " • E chi più di voi l ha vic ?\n",
      " • Non ve lo sent in cu \" che v op \" che v a \" che non vi las stare \" e n st tempo v at \" vi fa present una s di quiet \" di cons \" d una cons che sar pie \" i \" sub che voi lo rico \" lo confess \" l impl ? »\n",
      " • « Oh \" cer ! ho qui qual cosa che m op \" che mi rode !\n",
      " • Ma Dio !\n",
      " • Se c è questo Dio \" se è quell che di \" cosa vol che f di me ? »\n",
      " • Quest parole fur de con un accent disp ; ma Feder \" con un to sole \" come di placid is \" ris : « cosa pu far Dio di voi ? cosa vu far ?\n",
      " • Un seg della sua pot e della sua bon : vu ca da voi una glo che ness al gli pot dare .\n",
      " • Che il mondo grid da tanto tempo contro di voi \" che mill e mill voc detest le vos op . » ( l in si sc \" e rim stu un momento nel sent quel lingua cos in \"\n",
      "\n",
      "Example 2 — 18 predicted sentences:\n",
      " • i servi delle due part si sl all dif de loro pad .\n",
      " • Il combat era dis \" e per il numero \" e anche per Lod mi pi a scans i col \" e a disarm il ne \" che ad ; ma questo vol la mort di lui \" a ogni cost . Lod\n",
      " • a gi rice al bra sin una pug d un bravo \" e una s leg in una guan \" e il ne principal gli pi add per fin ; quando Cristo \" ved il suo pad ne est per \" and col pug add al sign . Quest\n",
      " • \" riv t la sua i contro di lui \" lo pass con la spa . A\n",
      " • quell vista \" Lod \" come fu di sé \" c la sua nel vent del fer \" il qual cad mori \" quasi a un punto col pov Cristo . I\n",
      " • bra del gent \" visto ch era fin \" si died all fug \" mal : quell di Lod \" tart e sf anche loro \" non essen più a chi dare \" e non vol trova imp nella gente \" che gi acc \" scan da al parte : e Lod si t solo \" con que due fun comp a pie \" in mezzo a una foll . «\n",
      " • Com è and ? –\n",
      " • uno . – Son\n",
      " • due . – Gli\n",
      " • ha fat un nel vent . – Chi è\n",
      " • stato a ? – Quel pre\n",
      " • . – Oh santa\n",
      " • Maria \" che s ! – Chi cerca\n",
      " • trova . – Una le\n",
      " • p tutte . – Ha fin\n",
      " • anche lui . – Che col\n",
      " • ! – Vu essere\n",
      " • una fac s . – E quell\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Example 0 — 6 predicted sentences\n",
      "\n",
      " • a cui dovevo tirare il collo \",\" per il banchetto di domenica \",\" e portateglieli ; perché non bisogna mai andar con le mani vòte da que' signori . Rac\n",
      " • contategli tutto l' accaduto ; e vedrete che vi dirà \",\" su due piedi \",\" di quelle cose che a noi non verrebbero in testa \",\" a pensarci un anno . » Renzo\n",
      " • abbracciò molto volentieri questo parere ; Lucia l' approvò ; e Agnese \",\" superba d' averlo dato \",\" levò \",\" a una a una \",\" le povere bestie dalla stìa \",\" riunì le loro otto gambe \",\" come se facesse un mazzetto di fiori \",\" le avvolse e le strinse con uno spago \",\" e le consegnò in mano a Renzo ; il quale \",\" date e ricevute parole di speranza \",\" uscì dalla parte dell' orto \",\" per non esser veduto da' ragazzi \",\" che gli correrebber dietro \",\" gridando : lo sposo ! lo sposo ! Co\n",
      " • sì \",\" attraversando i campi o \",\" come dicon colà \",\" i luoghi \",\" se n' andò per viottole \",\" fremendo \",\" ripensando alla sua disgrazia \",\" e ruminando il discorso da fare al dottor Azzecca-garbugli . Las\n",
      " • cio poi pensare al lettore \",\" come dovessero stare in viaggio quelle povere bestie \",\" così legate e tenute per le zampe \",\" a capo all' in giù \",\" nella mano d' un uomo il quale \",\" agitato da tante passioni \",\" accompagnava col gesto i pensieri che gli passavan a tumulto per la mente . Ora\n",
      " • stendeva il braccio per collera \",\" ora l' alzava per disperazione \",\" ora lo dibatteva in aria \",\"\n",
      "\n",
      "### Example 1 — 18 predicted sentences\n",
      "\n",
      " • più affettuosamente \",\" Federigo : « voi avete una buona nuova da darmi \",\" e me la fate tanto sospirare ? » «\n",
      " • Una buona nuova \",\" io ? Ho\n",
      " • l' inferno nel cuore ; e vi darò una buona nuova ? Dit\n",
      " • emi voi \",\" se lo sapete \",\" qual è questa buona nuova che aspettate da un par mio . » «\n",
      " • Che Dio v' ha toccato il cuore \",\" e vuol farvi suo \",\" » rispose pacatamente il cardinale . «\n",
      " • Dio ! Dio ! Dio ! Se\n",
      " • lo vedessi ! Se\n",
      " • lo sentissi ! Dov\n",
      " • ' è questo Dio ? » «\n",
      " • Voi me lo domandate ? voi ? E\n",
      " • chi più di voi l' ha vicino ? Non\n",
      " • ve lo sentite in cuore \",\" che v' opprime \",\" che v' agita \",\" che non vi lascia stare \",\" e nello stesso tempo v' attira \",\" vi fa presentire una speranza di quiete \",\" di consolazione \",\" d' una consolazione che sarà piena \",\" immensa \",\" subito che voi lo riconosciate \",\" lo confessiate \",\" l' imploriate ? » «\n",
      " • Oh \",\" certo ! ho qui qualche cosa che m' opprime \",\" che mi rode ! Ma\n",
      " • Dio ! Se\n",
      " • c' è questo Dio \",\" se è quello che dicono \",\" cosa volete che faccia di me ? » Quest\n",
      " • e parole furon dette con un accento disperato ; ma Federigo \",\" con un tono solenne \",\" come di placida ispirazione \",\" rispose : « cosa può far Dio di voi ? cosa vuol farne ? Un\n",
      " • segno della sua potenza e della sua bontà : vuol cavar da voi una gloria che nessun altro gli potrebbe dare . Che\n",
      " • il mondo gridi da tanto tempo contro di voi \",\" che mille e mille voci detestino le vostre opere ... » ( l' innominato si scosse \",\" e rimase stupefatto un momento nel sentir quel linguaggio così insolito \",\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Window 1\n",
      "P: più affettuosamente \",\" Federigo : « voi avete una buona nuova da darmi \",\" e me la fate tanto sospirare ? » « | Una buona nuova \",\" io ? Ho | l' inferno nel cuore ; e vi darò una buona nuova ? Dit | emi voi \",\" se lo sapete \",\" qual è questa buona nuova che aspettate da un par mio . » « | Che Dio v' ha toccato il cuore \",\" e vuol farvi suo \",\" » rispose pacatamente il cardinale . « | Dio ! Dio ! Dio ! Se | lo vedessi ! Se | lo sentissi ! Dov | ' è questo Dio ? » « | Voi me lo domandate ? voi ? E | chi più di voi l' ha vicino ? Non | ve lo sentite in cuore \",\" che v' opprime \",\" che v' agita \",\" che non vi lascia stare \",\" e nello stesso tempo v' attira \",\" vi fa presentire una speranza di quiete \",\" di consolazione \",\" d' una consolazione che sarà piena \",\" immensa \",\" subito che voi lo riconosciate \",\" lo confessiate \",\" l' imploriate ? » « | Oh \",\" certo ! ho qui qualche cosa che m' opprime \",\" che mi rode ! Ma | Dio ! Se | c' è questo Dio \",\" se è quello che dicono \",\" cosa volete che faccia di me ? » Quest | e parole furon dette con un accento disperato ; ma Federigo \",\" con un tono solenne \",\" come di placida ispirazione \",\" rispose : « cosa può far Dio di voi ? cosa vuol farne ? Un | segno della sua potenza e della sua bontà : vuol cavar da voi una gloria che nessun altro gli potrebbe dare . Che | il mondo gridi da tanto tempo contro di voi \",\" che mille e mille voci detestino le vostre opere ... » ( l' innominato si scosse \",\" e rimase stupefatto un momento nel sentir quel linguaggio così insolito \",\n",
      "G: più affettuosamente \",\" Federigo : « voi avete una buona nuova da darmi \",\" e me la fate tanto sospirare ? » « | Una buona nuova \",\" io ? Ho | l' inferno nel cuore ; e vi darò una buona nuova ? Dit | emi voi \",\" se lo sapete \",\" qual è questa buona nuova che aspettate da un par mio . » « | Che Dio v' ha toccato il cuore \",\" e vuol farvi suo \",\" » rispose pacatamente il cardinale . « | Dio ! Dio | ! Dio | ! Se | lo vedessi ! Se | lo sentissi ! Dov | ' è questo Dio ? » « | Voi me lo domandate ? voi ? E | chi più di voi l' ha vicino ? Non | ve lo sentite in cuore \",\" che v' opprime \",\" che v' agita \",\" che non vi lascia stare \",\" e nello stesso tempo v' attira \",\" vi fa presentire una speranza di quiete \",\" di consolazione \",\" d' una consolazione che sarà piena \",\" immensa \",\" subito che voi lo riconosciate \",\" lo confessiate \",\" l' imploriate ? » « | Oh \",\" certo ! ho qui qualche cosa che m' opprime \",\" che mi rode ! Ma | Dio ! Se | c' è questo Dio \",\" se è quello che dicono \",\" cosa volete che faccia di me ? » Quest | e parole furon dette con un accento disperato ; ma Federigo \",\" con un tono solenne \",\" come di placida ispirazione \",\" rispose : « cosa può far Dio di voi ? cosa vuol farne ? Un | segno della sua potenza e della sua bontà : vuol cavar da voi una gloria che nessun altro gli potrebbe dare . Che | il mondo gridi da tanto tempo contro di voi \",\" che mille e mille voci detestino le vostre opere ... » ( l' innominato si scosse \",\" e rimase stupefatto un momento nel sentir quel linguaggio così insolito \",\n",
      "\n",
      "### Window 2\n",
      "P: i servitori delle due parti si slanciarono alla difesa de' loro padroni . Il | combattimento era disuguale \",\" e per il numero \",\" e anche perché Lodovico mirava piuttosto a scansare i colpi \",\" e a disarmare il nemico \",\" che ad ucciderlo ; ma questo voleva la morte di lui \",\" a ogni costo . Lod | ovico aveva già ricevuta al braccio sinistro una pugnalata d' un bravo \",\" e una sgraffiatura leggiera in una guancia \",\" e il nemico principale gli piombava addosso per finirlo ; quando Cristoforo \",\" vedendo il suo padrone nell' estremo pericolo \",\" andò col pugnale addosso al signore . Quest | o \",\" rivolta tutta la sua ira contro di lui \",\" lo passò con la spada . A | quella vista \",\" Lodovico \",\" come fuor di sé \",\" cacciò la sua nel ventre del feritore \",\" il quale cadde moribondo \",\" quasi a un punto col povero Cristoforo . I | bravi del gentiluomo \",\" visto ch' era finita \",\" si diedero alla fuga \",\" malconci : quelli di Lodovico \",\" tartassati e sfregiati anche loro \",\" non essendovi più a chi dare \",\" e non volendo trovarsi impicciati nella gente \",\" che già accorreva \",\" scantonarono dall' altra parte : e Lodovico si trovò solo \",\" con que' due funesti compagni ai piedi \",\" in mezzo a una folla . « | Com' è andata ? – | È uno . – | Son due . – | Gli ha fatto un occhiello nel ventre . – | Chi è stato ammazzato ? – | Quel prepotente . – | Oh santa Maria \",\" che sconquasso ! – | Chi cerca trova . – | Una le paga tutte . – | Ha finito anche lui . – | Che colpo ! – | Vuol essere una faccenda seria . – | E quell'\n",
      "G: i servitori delle due parti si slanciarono alla difesa de' loro padroni . Il | combattimento era disuguale \",\" e per il numero \",\" e anche perché Lodovico mirava piuttosto a scansare i colpi \",\" e a disarmare il nemico \",\" che ad ucciderlo ; ma questo voleva la morte di lui \",\" a ogni costo . Lod | ovico aveva già ricevuta al braccio sinistro una pugnalata d' un bravo \",\" e una sgraffiatura leggiera in una guancia \",\" e il nemico principale gli piombava addosso per finirlo ; quando Cristoforo \",\" vedendo il suo padrone nell' estremo pericolo \",\" andò col pugnale addosso al signore . Quest | o \",\" rivolta tutta la sua ira contro di lui \",\" lo passò con la spada . A | quella vista \",\" Lodovico \",\" come fuor di sé \",\" cacciò la sua nel ventre del feritore \",\" il quale cadde moribondo \",\" quasi a un punto col povero Cristoforo . I | bravi del gentiluomo \",\" visto ch' era finita \",\" si diedero alla fuga \",\" malconci : quelli di Lodovico \",\" tartassati e sfregiati anche loro \",\" non essendovi più a chi dare \",\" e non volendo trovarsi impicciati nella gente \",\" che già accorreva \",\" scantonarono dall' altra parte : e Lodovico si trovò solo \",\" con que' due funesti compagni ai piedi \",\" in mezzo a una folla . « | Com' è andata ? – | È uno . – | Son due . – | Gli ha fatto un occhiello nel ventre . – | Chi è stato ammazzato ? – | Quel prepotente . – | Oh santa Maria \",\" che sconquasso ! – | Chi cerca trova . – | Una le paga tutte . – | Ha finito anche lui . – | Che colpo ! – | Vuol essere una faccenda seria . – | E quell'\n",
      "\n",
      "### Window 3\n",
      "P: si strinsero intorno al frate . In | tanto vennero servitori \",\" con gran copia di rinfreschi . Il | gentiluomo si raccostò al nostro Cristoforo \",\" il quale faceva segno di volersi licenziare \",\" e gli disse : « padre \",\" gradisca qualche cosa ; mi dia questa prova d' amicizia . » E | si mise per servirlo prima d' ogni altro ; ma egli \",\" ritirandosi \",\" con una certa resistenza cordiale \",\" « queste cose \",\" » disse \",\" « non fanno più per me ; ma non sarà mai ch' io rifiuti i suoi doni . I | o sto per mettermi in viaggio : si degni di farmi portare un pane \",\" perché io possa dire d' aver goduto la sua carità \",\" d' aver mangiato il suo pane \",\" e avuto un segno del suo perdono . » Il | gentiluomo \",\" commosso \",\" ordinò che così si facesse ; e venne subito un cameriere \",\" in gran gala \",\" portando un pane sur un piatto d' argento \",\" e lo presentò al padre ; il quale \",\" presolo e ringraziato \",\" lo mise nella sporta . Chi | ese quindi licenza ; e \",\" abbracciato di nuovo il padron di casa \",\" e tutti quelli che \",\" trovandosi più vicini a lui \",\" poterono impadronirsene un momento \",\" si liberò da essi a fatica ; ebbe a combatter nell' anticamere \",\" per isbrigarsi da' servitori \",\" e anche da' bravi \",\" che gli baciavano il lembo dell' abito \",\" il cordone \",\" il cappuccio ; e si trovò nella strada \",\" portato come in trionfo \",\" e accompagnato da una folla di popolo \",\" fino a una porta della città ; d' onde uscì \",\" cominciando\n",
      "G: si strinsero intorno al frate . In | tanto vennero servitori \",\" con gran copia di rinfreschi . Il | gentiluomo si raccostò al nostro Cristoforo \",\" il quale faceva segno di volersi licenziare \",\" e gli disse : « padre \",\" gradisca qualche cosa ; mi dia questa prova d' amicizia . » E | si mise per servirlo prima d' ogni altro ; ma egli \",\" ritirandosi \",\" con una certa resistenza cordiale \",\" « queste cose \",\" » disse \",\" « non fanno più per me ; ma non sarà mai ch' io rifiuti i suoi doni . I | o sto per mettermi in viaggio : si degni di farmi portare un pane \",\" perché io possa dire d' aver goduto la sua carità \",\" d' aver mangiato il suo pane \",\" e avuto un segno del suo perdono . » Il | gentiluomo \",\" commosso \",\" ordinò che così si facesse ; e venne subito un cameriere \",\" in gran gala \",\" portando un pane sur un piatto d' argento \",\" e lo presentò al padre ; il quale \",\" presolo e ringraziato \",\" lo mise nella sporta . Chi | ese quindi licenza ; e \",\" abbracciato di nuovo il padron di casa \",\" e tutti quelli che \",\" trovandosi più vicini a lui \",\" poterono impadronirsene un momento \",\" si liberò da essi a fatica ; ebbe a combatter nell' anticamere \",\" per isbrigarsi da' servitori \",\" e anche da' bravi \",\" che gli baciavano il lembo dell' abito \",\" il cordone \",\" il cappuccio ; e si trovò nella strada \",\" portato come in trionfo \",\" e accompagnato da una folla di popolo \",\" fino a una porta della città ; d' onde uscì \",\" cominciando\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(evaluation)\n",
    "best_key = max(results, key=lambda k: results[k][\"eval_f1\"])\n",
    "model_dir = paths.chekpoints/best_key\n",
    "best_trainer = evaluation.load_trainer_for_eval(model_dir, HF_DATA/best_key/\"val\")\n",
    "val_ds = load_from_disk(HF_DATA/best_key/\"val\")\n",
    "\n",
    "pred = best_trainer.predict(val_ds)  # logits + label_ids as np arrays\n",
    "logits = pred.predictions\n",
    "label_ids = pred.label_ids\n",
    "tok = best_trainer.tokenizer\n",
    "\n",
    "def sentences_from_word_seq(words, y_pred):\n",
    "    sents, cur = [], []\n",
    "    for w, b in zip(words, y_pred):\n",
    "        cur.append(w)\n",
    "        if b == 1:\n",
    "            sents.append(cur); cur = []\n",
    "    if cur: sents.append(cur)\n",
    "    return sents\n",
    "\n",
    "for i in range(min(3, len(val_ds))):\n",
    "    ids = val_ds[i][\"input_ids\"]\n",
    "    words = tok.convert_ids_to_tokens(ids)\n",
    "\n",
    "    mask = (label_ids[i] != -100)          # np.bool_ array\n",
    "    y_pred = logits[i].argmax(-1)[mask]    # predicted boundary labels at visible positions\n",
    "    visible_words = [w for w, m in zip(words, mask.tolist()) if m]\n",
    "\n",
    "    sents = sentences_from_word_seq(visible_words, y_pred)\n",
    "    print(f\"\\nWindow {i} — predicted {len(sents)} sentences:\")\n",
    "    print(\" | \".join([\" \".join(s) for s in sents]))\n",
    "\n",
    "\n",
    "evaluation.preview_predictions(best_trainer, val_ds, k=3)\n",
    "evaluation.preview_full_sentences(best_trainer, val_ds, n_examples=2)\n",
    "evaluation.preview_pred_vs_gold(best_trainer, val_ds, [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4912b939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁più ▁aff ▁\" ▁Feder ▁: ▁« ▁voi ▁a ▁una ▁bu ▁nu ▁da ▁dar ▁\" ▁e ▁me ▁la ▁fate ▁tanto ▁so ▁? ▁»▌ ▁« ▁Una ▁bu ▁nu ▁\" ▁io ▁?▌ ▁Ho ▁l ▁inferno ▁nel ▁cu ▁; ▁e ▁vi ▁dar ▁una ▁bu ▁nu ▁?▌ ▁Dit ▁voi ▁\" ▁se ▁lo ▁sap ▁\" ▁qual ▁è ▁quest ▁bu ▁nu ▁che ▁as ▁da ▁un ▁par ▁mio ▁. ▁»▌ ▁« ▁Che ▁Dio ▁v ▁ha ▁to ▁il ▁cu ▁\" ▁e ▁vu ▁far ▁suo ▁\" ▁» ▁ris ▁pa ▁il ▁cardinal ▁.▌ ▁« ▁Dio ▁! ▁Dio ▁! ▁Dio ▁!▌ ▁Se ▁lo ▁ved ▁!▌ ▁Se ▁lo ▁sent ▁!▌ ▁Dov ▁è ▁questo ▁Dio ▁? ▁»▌ ▁« ▁Voi ▁me ▁lo ▁do ▁? ▁voi ▁?▌ ▁E ▁chi ▁più ▁di ▁voi ▁l ▁ha ▁vic ▁?▌ ▁Non ▁ve ▁lo ▁sent ▁in ▁cu ▁\" ▁che ▁v ▁op ▁\" ▁che ▁v ▁a ▁\" ▁che ▁non ▁vi ▁las ▁stare ▁\" ▁e ▁n ▁st ▁tempo ▁v ▁at ▁\" ▁vi ▁fa ▁present ▁una ▁s ▁di ▁quiet ▁\" ▁di ▁cons ▁\" ▁d ▁una ▁cons ▁che ▁sar ▁pie ▁\" ▁i ▁\" ▁sub ▁che ▁voi ▁lo ▁rico ▁\" ▁lo ▁confess ▁\" ▁l ▁impl ▁? ▁»▌ ▁« ▁Oh ▁\" ▁cer ▁! ▁ho ▁qui ▁qual ▁cosa ▁che ▁m ▁op ▁\" ▁che ▁mi ▁rode ▁!▌ ▁Ma ▁Dio ▁!▌ ▁Se ▁c ▁è ▁questo ▁Dio ▁\" ▁se ▁è ▁quell ▁che ▁di ▁\" ▁cosa ▁vol ▁che ▁f ▁di ▁me ▁? ▁»▌ ▁Quest ▁parole ▁fur ▁de ▁con ▁un ▁accent ▁disp ▁; ▁ma ▁Feder ▁\" ▁con ▁un ▁to ▁sole ▁\" ▁come ▁di ▁placid ▁is ▁\" ▁ris ▁: ▁« ▁cosa ▁pu ▁far ▁Dio ▁di ▁voi ▁? ▁cosa ▁vu ▁far ▁?▌ ▁Un ▁seg ▁della ▁sua ▁pot ▁e ▁della ▁sua ▁bon ▁: ▁vu ▁ca ▁da ▁voi ▁una ▁glo ▁che ▁ness ▁al ▁gli ▁pot ▁dare ▁.▌ ▁Che ▁il ▁mondo ▁grid ▁da ▁tanto ▁tempo ▁contro ▁di ▁voi ▁\" ▁che ▁mill ▁e ▁mill ▁voc ▁detest ▁le ▁vos ▁op ▁. ▁» ▁( ▁l ▁in ▁si ▁sc ▁\" ▁e ▁rim ▁stu ▁un ▁momento ▁nel ▁sent ▁quel ▁lingua ▁cos ▁in ▁\"\n",
      "▁in ▁comp ▁\" ▁be ▁; ▁a ▁\" ▁tu ▁pu ▁be ▁dorm ▁una ▁not ▁in ▁terra ▁.▌ ▁Fall ▁cor ▁\" ▁ti ▁di ▁; ▁tie ▁all ▁.▌ ▁E ▁che ▁non ▁a ▁a ▁lament ▁di ▁te ▁! ▁»▌ ▁Co ▁det ▁\" ▁si ▁moss ▁rapid ▁verso ▁l ▁us ▁.▌ ▁Lucia ▁s ▁a ▁e ▁co ▁per ▁tra ▁\" ▁e ▁rin ▁la ▁sua ▁pre ▁; ▁ma ▁era ▁spa ▁.▌ ▁« ▁Oh ▁po ▁me ▁!▌ ▁Chi ▁\" ▁chi ▁sub ▁. ▁»▌ ▁E ▁sent ▁ch ▁ebb ▁acc ▁i ▁batten ▁e ▁sc ▁il ▁pal ▁\" ▁torn ▁a ▁ran ▁nel ▁suo ▁can ▁.▌ ▁« ▁Oh ▁po ▁me ▁! ▁» ▁es ▁di ▁nu ▁sing ▁: ▁« ▁chi ▁pre ▁or ▁?▌ ▁Dove ▁sono ▁?▌ ▁Dit ▁voi ▁\" ▁dit ▁per ▁car ▁\" ▁chi ▁è ▁quel ▁sign ▁. ▁quell ▁che ▁m ▁ha ▁par ▁? ▁»▌ ▁« ▁Chi ▁è ▁\" ▁eh ▁? ▁chi ▁è ▁?▌ ▁Vol ▁ch ▁io ▁ve ▁lo ▁di ▁.▌ ▁Asp ▁ch ▁io ▁te ▁lo ▁di ▁.▌ ▁Per ▁vi ▁prote ▁\" ▁a ▁mess ▁su ▁superb ▁; ▁e ▁vol ▁ ▁so ▁voi ▁\" ▁e ▁far ▁and ▁di ▁mezzo ▁me ▁.▌ ▁Do ▁a ▁lui ▁.▌ ▁S ▁io ▁vi ▁content ▁anche ▁in ▁questo ▁\" ▁non ▁mi ▁to ▁di ▁quell ▁bu ▁parole ▁che ▁a ▁sent ▁voi ▁. ▁»▌ ▁– ▁I ▁son ▁ve ▁\" ▁son ▁ve ▁\" ▁– ▁continu ▁\" ▁mor ▁tra ▁i ▁dent ▁.▌ ▁– ▁Male ▁le ▁gi ▁\" ▁che ▁fan ▁be ▁ve ▁a ▁pi ▁e ▁a ▁ride ▁\" ▁e ▁hanno ▁sempre ▁rag ▁. ▁– ▁Ma ▁sent ▁Lucia ▁sing ▁\" ▁e ▁torn ▁min ▁all ▁men ▁il ▁com ▁del ▁pad ▁\" ▁si ▁chin ▁verso ▁la ▁po ▁rin ▁\" ▁e ▁\" ▁con ▁voce ▁rad ▁\" ▁rip ▁: ▁« ▁via ▁\" ▁non ▁v ▁ho ▁det ▁n ▁di ▁male ▁: ▁state ▁all ▁.▌ ▁Non ▁mi ▁do ▁di ▁quell ▁co ▁che ▁non ▁vi ▁poss ▁dire ▁; ▁e ▁del ▁rest ▁\" ▁state ▁di ▁bu\n",
      "▁\" ▁e ▁in ▁più ▁minut ▁dai ▁pic ▁compar ▁delle ▁vet ▁.▌ ▁Un ▁qual ▁demon ▁\" ▁o ▁. ▁un ▁qual ▁angel ▁che ▁la ▁prote ▁. ▁.▌ ▁Compassion ▁al ▁Nib ▁! ▁.▌ ▁Do ▁\" ▁do ▁di ▁bu ▁or ▁\" ▁fu ▁di ▁qui ▁cost ▁; ▁al ▁suo ▁des ▁\" ▁e ▁non ▁se ▁ne ▁par ▁più ▁\" ▁e ▁\" ▁– ▁prose ▁tra ▁sé ▁\" ▁con ▁quell ▁an ▁con ▁cui ▁si ▁com ▁a ▁un ▁rag ▁in ▁\" ▁sap ▁che ▁non ▁u ▁\" ▁– ▁e ▁non ▁ci ▁si ▁pens ▁più ▁.▌ ▁Que ▁animal ▁di ▁don ▁Rodrigo ▁non ▁mi ▁v ▁a ▁romper ▁la ▁test ▁con ▁ring ▁; ▁che ▁. ▁non ▁v ▁più ▁sent ▁par ▁di ▁cost ▁.▌ ▁L ▁ho ▁servi ▁per ▁. ▁per ▁ho ▁prom ▁: ▁e ▁ho ▁prom ▁per ▁. ▁è ▁il ▁mio ▁des ▁.▌ ▁Ma ▁v ▁che ▁me ▁lo ▁p ▁be ▁questo ▁servi ▁\" ▁co ▁.▌ ▁Ved ▁un ▁poco ▁.▌ ▁–▌ ▁E ▁vol ▁almanac ▁cosa ▁a ▁pot ▁rich ▁di ▁scab ▁\" ▁per ▁comp ▁\" ▁e ▁quasi ▁per ▁pen ▁; ▁ma ▁gli ▁si ▁at ▁di ▁nu ▁all ▁men ▁quell ▁parole ▁: ▁compassion ▁al ▁Nib ▁!▌ ▁– ▁Come ▁pu ▁a ▁fat ▁cost ▁? ▁– ▁continua ▁\" ▁stra ▁da ▁quel ▁pens ▁.▌ ▁– ▁V ▁ved ▁.▌ ▁Eh ▁! ▁no ▁.▌ ▁S ▁\" ▁v ▁ved ▁. ▁–▌ ▁E ▁d ▁una ▁stanza ▁in ▁un ▁al ▁\" ▁t ▁una ▁scale ▁\" ▁e ▁su ▁a ▁ta ▁\" ▁and ▁all ▁camera ▁della ▁ve ▁\" ▁e ▁pic ▁all ▁us ▁con ▁un ▁calci ▁.▌ ▁« ▁Chi ▁è ▁? ▁»▌ ▁« ▁Apr ▁. ▁»▌ ▁A ▁quell ▁voce ▁\" ▁la ▁ve ▁f ▁tre ▁salt ▁; ▁e ▁sub ▁si ▁sent ▁sc ▁il ▁pal ▁negli ▁an ▁\" ▁e ▁l ▁us ▁si ▁spa ▁.▌ ▁L ▁in ▁\" ▁dalla ▁so ▁\" ▁died ▁un ▁ ▁in ▁g ▁; ▁e ▁\" ▁al ▁ ▁d ▁una ▁luc ▁che ▁a ▁sur ▁un ▁ta\n",
      "e ▁\" ▁et ▁m ▁pen ▁pec ▁et ▁an ▁corporal ▁sino ▁all ▁gal ▁\" ▁all ▁ ▁di ▁S ▁\" ▁second ▁la ▁qual ▁de ▁casi ▁et ▁delle ▁person ▁.▌ ▁Al ▁ris ▁b ▁era ▁gi ▁stato ▁f ▁il ▁prezzo ▁prima ▁della ▁so ▁; ▁come ▁prob ▁la ▁tariff ▁o ▁\" ▁per ▁us ▁quell ▁den ▁celeb ▁negli ▁an ▁modern ▁\" ▁il ▁maximum ▁del ▁gran ▁e ▁dell ▁alt ▁gran ▁più ▁or ▁sar ▁stato ▁f ▁con ▁alt ▁grid ▁\" ▁che ▁non ▁c ▁è ▁av ▁di ▁ve ▁.▌ ▁Man ▁cos ▁il ▁pane ▁e ▁la ▁far ▁a ▁bu ▁merc ▁in ▁Milano ▁\" ▁ne ▁veni ▁di ▁cons ▁che ▁dalla ▁camp ▁acc ▁gente ▁a ▁procession ▁a ▁comprar ▁.▌ ▁Don ▁Gonzalo ▁\" ▁per ▁rip ▁a ▁questo ▁\" ▁come ▁dice ▁lui ▁\" ▁inconvenient ▁\" ▁pro ▁\" ▁con ▁un ▁al ▁grid ▁del ▁15 ▁di ▁dic ▁\" ▁di ▁port ▁fu ▁della ▁cit ▁pane ▁\" ▁per ▁più ▁del ▁valor ▁di ▁vent ▁sold ▁; ▁pen ▁la ▁per ▁del ▁pane ▁me ▁\" ▁e ▁vent ▁sc ▁\" ▁et ▁in ▁caso ▁di ▁in ▁\" ▁di ▁due ▁tra ▁di ▁cord ▁in ▁public ▁\" ▁et ▁m ▁pen ▁an ▁\" ▁second ▁il ▁so ▁\" ▁all ▁ ▁di ▁S ▁Il ▁22 ▁dello ▁st ▁me ▁( ▁e ▁non ▁si ▁ve ▁per ▁cos ▁t ▁) ▁\" ▁pub ▁un ▁or ▁so ▁per ▁le ▁far ▁e ▁per ▁i ▁gran ▁.▌ ▁La ▁molt ▁a ▁vol ▁far ▁nas ▁l ▁ab ▁col ▁sac ▁e ▁con ▁l ▁in ▁; ▁il ▁govern ▁vol ▁man ▁con ▁la ▁gal ▁e ▁con ▁la ▁cord ▁.▌ ▁I ▁me ▁era ▁convenient ▁tra ▁loro ▁; ▁ma ▁cosa ▁a ▁a ▁fare ▁col ▁fine ▁\" ▁il ▁let ▁lo ▁ve ▁: ▁come ▁va ▁in ▁fat ▁ad ▁o ▁\" ▁lo ▁ved ▁a ▁moment ▁.▌ ▁ ▁poi ▁facile ▁anche ▁ve ▁\" ▁e ▁non ▁in ▁l ▁oss ▁come ▁tra ▁que ▁stran ▁pro\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Window 1\n",
      "P: più affettuosamente \",\" Federigo : « voi avete una buona nuova da darmi \",\" e me la fate tanto sospirare ? » « | Una buona nuova \",\" io ? Ho | l' inferno nel cuore ; e vi darò una buona nuova ? Dit | emi voi \",\" se lo sapete \",\" qual è questa buona nuova che aspettate da un par mio . » « | Che Dio v' ha toccato il cuore \",\" e vuol farvi suo \",\" » rispose pacatamente il cardinale . « | Dio ! Dio ! Dio ! Se | lo vedessi ! Se | lo sentissi ! Dov | ' è questo Dio ? » « | Voi me lo domandate ? voi ? E | chi più di voi l' ha vicino ? Non | ve lo sentite in cuore \",\" che v' opprime \",\" che v' agita \",\" che non vi lascia stare \",\" e nello stesso tempo v' attira \",\" vi fa presentire una speranza di quiete \",\" di consolazione \",\" d' una consolazione che sarà piena \",\" immensa \",\" subito che voi lo riconosciate \",\" lo confessiate \",\" l' imploriate ? » « | Oh \",\" certo ! ho qui qualche cosa che m' opprime \",\" che mi rode ! Ma | Dio ! Se | c' è questo Dio \",\" se è quello che dicono \",\" cosa volete che faccia di me ? » Quest | e parole furon dette con un accento disperato ; ma Federigo \",\" con un tono solenne \",\" come di placida ispirazione \",\" rispose : « cosa può far Dio di voi ? cosa vuol farne ? Un | segno della sua potenza e della sua bontà : vuol cavar da voi una gloria che nessun altro gli potrebbe dare . Che | il mondo gridi da tanto tempo contro di voi \",\" che mille e mille voci detestino le vostre opere ... » ( l' innominato si scosse \",\" e rimase stupefatto un momento nel sentir quel linguaggio così insolito \",\n",
      "G: più affettuosamente \",\" Federigo : « voi avete una buona nuova da darmi \",\" e me la fate tanto sospirare ? » « | Una buona nuova \",\" io ? Ho | l' inferno nel cuore ; e vi darò una buona nuova ? Dit | emi voi \",\" se lo sapete \",\" qual è questa buona nuova che aspettate da un par mio . » « | Che Dio v' ha toccato il cuore \",\" e vuol farvi suo \",\" » rispose pacatamente il cardinale . « | Dio ! Dio | ! Dio | ! Se | lo vedessi ! Se | lo sentissi ! Dov | ' è questo Dio ? » « | Voi me lo domandate ? voi ? E | chi più di voi l' ha vicino ? Non | ve lo sentite in cuore \",\" che v' opprime \",\" che v' agita \",\" che non vi lascia stare \",\" e nello stesso tempo v' attira \",\" vi fa presentire una speranza di quiete \",\" di consolazione \",\" d' una consolazione che sarà piena \",\" immensa \",\" subito che voi lo riconosciate \",\" lo confessiate \",\" l' imploriate ? » « | Oh \",\" certo ! ho qui qualche cosa che m' opprime \",\" che mi rode ! Ma | Dio ! Se | c' è questo Dio \",\" se è quello che dicono \",\" cosa volete che faccia di me ? » Quest | e parole furon dette con un accento disperato ; ma Federigo \",\" con un tono solenne \",\" come di placida ispirazione \",\" rispose : « cosa può far Dio di voi ? cosa vuol farne ? Un | segno della sua potenza e della sua bontà : vuol cavar da voi una gloria che nessun altro gli potrebbe dare . Che | il mondo gridi da tanto tempo contro di voi \",\" che mille e mille voci detestino le vostre opere ... » ( l' innominato si scosse \",\" e rimase stupefatto un momento nel sentir quel linguaggio così insolito \",\n",
      "\n",
      "### Window 6\n",
      "P: in compagnia \",\" bene ; altrimenti \",\" tu puoi ben dormire una notte in terra . Fall | e coraggio \",\" ti dico ; tienla allegra . E | che non abbia a lamentarsi di te ! » Co | sì detto \",\" si mosse rapidamente verso l' uscio . Lucia | s' alzò e corse per trattenerlo \",\" e rinnovare la sua preghiera ; ma era sparito . « | Oh povera me ! Chi | udete \",\" chiudete subito . » E | sentito ch' ebbe accostare i battenti e scorrere il paletto \",\" tornò a rannicchiarsi nel suo cantuccio . « | Oh povera me ! » esclamò di nuovo singhiozzando : « chi pregherò ora ? Dove | sono ? Dit | emi voi \",\" ditemi per carità \",\" chi è quel signore ... quello che m' ha parlato ? » « | Chi è \",\" eh ? chi è ? Vol | ete ch' io ve lo dica . Asp | etta ch' io te lo dica . Per | ché vi protegge \",\" avete messo su superbia ; e volete esser soddisfatta voi \",\" e farne andar di mezzo me . Do | mandatene a lui . S | ' io vi contentassi anche in questo \",\" non mi toccherebbe di quelle buone parole che avete sentite voi . » – | Io son vecchia \",\" son vecchia \",\" – continuò \",\" mormorando tra i denti . – | Maledette le giovani \",\" che fanno bel vedere a piangere e a ridere \",\" e hanno sempre ragione . – Ma sentendo Lucia singhiozzare \",\" e tornandole minaccioso alla mente il comando del padrone \",\" si chinò verso la povera rincantucciata \",\" e \",\" con voce raddolcita \",\" riprese : « via \",\" non v' ho detto niente di male : state allegra . Non | mi domandate di quelle cose che non vi posso dire ; e del resto \",\" state di buon\n",
      "G: in compagnia \",\" bene ; altrimenti \",\" tu puoi ben dormire una notte in terra . Fall | e coraggio \",\" ti dico ; tienla allegra . E | che non abbia a lamentarsi di te ! » Co | sì detto \",\" si mosse rapidamente verso l' uscio . Lucia | s' alzò e corse per trattenerlo \",\" e rinnovare la sua preghiera ; ma era sparito . « | Oh povera me ! Chi | udete \",\" chiudete subito . » E | sentito ch' ebbe accostare i battenti e scorrere il paletto \",\" tornò a rannicchiarsi nel suo cantuccio . « | Oh povera me ! » esclamò di nuovo singhiozzando : « chi pregherò ora ? Dove | sono ? Dit | emi voi \",\" ditemi per carità \",\" chi è quel signore ... quello che m' ha parlato ? » « | Chi è \",\" eh ? chi è ? Vol | ete ch' io ve lo dica . Asp | etta ch' io te lo dica . Per | ché vi protegge \",\" avete messo su superbia ; e volete esser soddisfatta voi \",\" e farne andar di mezzo me . Do | mandatene a lui . S | ' io vi contentassi anche in questo \",\" non mi toccherebbe di quelle buone parole che avete sentite voi . » – | Io son vecchia \",\" son vecchia \",\" – continuò \",\" mormorando tra i denti . – | Maledette le giovani \",\" che fanno bel vedere a piangere e a ridere \",\" e hanno sempre ragione . – Ma | sentendo Lucia singhiozzare \",\" e tornandole minaccioso alla mente il comando del padrone \",\" si chinò verso la povera rincantucciata \",\" e \",\" con voce raddolcita \",\" riprese : « via \",\" non v' ho detto niente di male : state allegra . Non | mi domandate di quelle cose che non vi posso dire ; e del resto \",\" state di buon\n",
      "\n",
      "### Window 35\n",
      "P: \",\" e intagliata più minutamente dai piccoli compartimenti delle vetriate . Un | qualche demonio \",\" o ... un qualche angelo che la protegge . . Compassion | e al Nibbio ! .. | . Domattina \",\" domattina di buon' ora \",\" fuor di qui costei ; al suo destino \",\" e non se ne parli più \",\" e \",\" – proseguiva tra sé \",\" con quell' animo con cui si comanda a un ragazzo indocile \",\" sapendo che non ubbidirà \",\" – e non ci si pensi più . Que | ll' animale di don Rodrigo non mi venga a romper la testa con ringraziamenti ; che ... non voglio più sentir parlar di costei . L | ' ho servito perché ... perché ho promesso : e ho promesso perché ... è il mio destino . Ma | voglio che me lo paghi bene questo servizio \",\" colui . Ved | iamo un poco .. | . – E | voleva almanaccare cosa avrebbe potuto richiedergli di scabroso \",\" per compenso \",\" e quasi per pena ; ma gli si attraversaron di nuovo alla mente quelle parole : compassione al Nibbio ! – | Come può aver fatto costei ? – continuava \",\" strascinato da quel pensiero . – | Voglio vederla .. | . Eh ! no .. | . Sì \",\" voglio vederla . – E | d' una stanza in un' altra \",\" trovò una scaletta \",\" e su a tastone \",\" andò alla camera della vecchia \",\" e picchiò all' uscio con un calcio . « | Chi è ? » « | Apri . » A | quella voce \",\" la vecchia fece tre salti ; e subito si sentì scorrere il paletto negli anelli \",\" e l' uscio si spalancò . L | ' innominato \",\" dalla soglia \",\" diede un' occhiata in giro ; e \",\" al lume d' una lucerna che ardeva sur un ta\n",
      "G: \",\" e intagliata più minutamente dai piccoli compartimenti delle vetriate . Un | qualche demonio \",\" o ... un qualche angelo che la protegge . . Compassion | e al Nibbio ! .. | . Domattina \",\" domattina di buon' ora \",\" fuor di qui costei ; al suo destino \",\" e non se ne parli più \",\" e \",\" – proseguiva tra sé \",\" con quell' animo con cui si comanda a un ragazzo indocile \",\" sapendo che non ubbidirà \",\" – e non ci si pensi più . Que | ll' animale di don Rodrigo non mi venga a romper la testa con ringraziamenti ; che ... non voglio più sentir parlar di costei . L | ' ho servito perché ... perché ho promesso : e ho promesso perché ... è il mio destino . Ma | voglio che me lo paghi bene questo servizio \",\" colui . Ved | iamo un poco ... – E | voleva almanaccare cosa avrebbe potuto richiedergli di scabroso \",\" per compenso \",\" e quasi per pena ; ma gli si attraversaron di nuovo alla mente quelle parole : compassione al Nibbio ! – | Come può aver fatto costei ? – continuava \",\" strascinato da quel pensiero . – | Voglio vederla .. | . Eh ! no .. | . Sì \",\" voglio vederla . – E | d' una stanza in un' altra \",\" trovò una scaletta \",\" e su a tastone \",\" andò alla camera della vecchia \",\" e picchiò all' uscio con un calcio . « | Chi è ? » « | Apri . » A | quella voce \",\" la vecchia fece tre salti ; e subito si sentì scorrere il paletto negli anelli \",\" e l' uscio si spalancò . L | ' innominato \",\" dalla soglia \",\" diede un' occhiata in giro ; e \",\" al lume d' una lucerna che ardeva sur un ta\n",
      "\n",
      "### Window 48\n",
      "P: e \",\" et maggior pena pecuniaria et ancora corporale sino alla galera \",\" all' arbitrio di S.E. \",\" secondo la qualità de' casi et delle persone . Al | riso brillato era già stato fissato il prezzo prima della sommossa ; come probabilmente la tariffa o \",\" per usare quella denominazione celeberrima negli annali moderni \",\" il maximum del grano e dell' altre granaglie più ordinarie sarà stato fissato con altre gride \",\" che non c' è avvenuto di vedere . Man | tenuto così il pane e la farina a buon mercato in Milano \",\" ne veniva di conseguenza che dalla campagna accorresse gente a processione a comprarne . Don | Gonzalo \",\" per riparare a questo \",\" come dice lui \",\" inconveniente \",\" proibì \",\" con un' altra grida del 15 di dicembre \",\" di portar fuori della città pane \",\" per più del valore di venti soldi ; pena la perdita del pane medesimo \",\" e venticinque scudi \",\" et in caso di inhabilità \",\" di due tratti di corda in publico \",\" et maggior pena ancora \",\" secondo il solito \",\" all' arbitrio di S.E. Il 22 dello stesso mese ( e non si vede perché così tardi ) \",\" pubblicò un ordine somigliante per le farine e per i grani . La | moltitudine aveva voluto far nascere l' abbondanza col saccheggio e con l' incendio ; il governo voleva mantenerla con la galera e con la corda . I | mezzi erano convenienti tra loro ; ma cosa avessero a fare col fine \",\" il lettore lo vede : come valessero in fatto ad ottenerlo \",\" lo vedrà a momenti . | È poi facile anche vedere \",\" e non inutile l' osservare come tra quegli strani provvedimenti\n",
      "G: e \",\" et maggior pena pecuniaria et ancora corporale sino alla galera \",\" all' arbitrio di S.E. \",\" secondo la qualità de' casi et delle persone . Al | riso brillato era già stato fissato il prezzo prima della sommossa ; come probabilmente la tariffa o \",\" per usare quella denominazione celeberrima negli annali moderni \",\" il maximum del grano e dell' altre granaglie più ordinarie sarà stato fissato con altre gride \",\" che non c' è avvenuto di vedere . Man | tenuto così il pane e la farina a buon mercato in Milano \",\" ne veniva di conseguenza che dalla campagna accorresse gente a processione a comprarne . Don | Gonzalo \",\" per riparare a questo \",\" come dice lui \",\" inconveniente \",\" proibì \",\" con un' altra grida del 15 di dicembre \",\" di portar fuori della città pane \",\" per più del valore di venti soldi ; pena la perdita del pane medesimo \",\" e venticinque scudi \",\" et in caso di inhabilità \",\" di due tratti di corda in publico \",\" et maggior pena ancora \",\" secondo il solito \",\" all' arbitrio di S. | E. Il 22 dello stesso mese ( e non si vede perché così tardi ) \",\" pubblicò un ordine somigliante per le farine e per i grani . La | moltitudine aveva voluto far nascere l' abbondanza col saccheggio e con l' incendio ; il governo voleva mantenerla con la galera e con la corda . I | mezzi erano convenienti tra loro ; ma cosa avessero a fare col fine \",\" il lettore lo vede : come valessero in fatto ad ottenerlo \",\" lo vedrà a momenti . | È poi facile anche vedere \",\" e non inutile l' osservare come tra quegli strani provvedimenti\n"
     ]
    }
   ],
   "source": [
    "def error_examples(trainer, ds, max_show=10):\n",
    "    out = trainer.predict(ds)\n",
    "    preds = out.predictions.argmax(-1)\n",
    "    labels = out.label_ids\n",
    "    mask = labels != -100\n",
    "    ids = ds[\"input_ids\"]\n",
    "    tok = trainer.tokenizer\n",
    "    shown = 0\n",
    "    results = []\n",
    "    for i in range(len(ds)):\n",
    "        m = mask[i]\n",
    "        if not m.any(): continue\n",
    "        y_true = labels[i][m]\n",
    "        y_pred = preds[i][m]\n",
    "        if (y_true != y_pred).any():\n",
    "            results.append(i)\n",
    "            words = tok.convert_ids_to_tokens(ds[i][\"input_ids\"])\n",
    "            visible_words = [w for w,mm in zip(words, m) if mm]\n",
    "            # mark predicted boundaries with \"▌\"\n",
    "            pieces = []\n",
    "            for w, b, t in zip(visible_words, y_pred, y_true):\n",
    "                mark = \"▌\" if b==1 else \"\"\n",
    "                pieces.append(w+mark)\n",
    "            print(\" \".join(pieces))\n",
    "            shown += 1\n",
    "            if shown >= max_show: break\n",
    "    return results\n",
    "\n",
    "results = error_examples(best_trainer, val_ds, max_show=5)\n",
    "evaluation.preview_pred_vs_gold(best_trainer, val_ds, results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13570eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/deberta-v3-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fb0ec8a0254bcf8cd4a08a57b895a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8785cb360b254b4dab1175246315fa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ce7fd7cf5f49b4800ea1654e4c21fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answerdotai/ModernBERT-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acff919c17cb421b876bd7f0e241fab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103952124949493c8e5c9393d2a6cfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b1c816fe5744b29dfcf8f495786c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-multilingual-cased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997959fb8a874a9182cb7ac66df452ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdb480cde74493296267c9092403503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de15fc292c6f4f14bc5b0e399b2099f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/notebooks/../src/evaluation.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deberta OOD Results: {'precision': 0.9207920792079208, 'recall': 0.8857142857142857, 'f1': 0.9029126213592233, 'accuracy': 0.9882214369846879}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/notebooks/../src/evaluation.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modernbert OOD Results: {'precision': 0.8375, 'recall': 0.6907216494845361, 'f1': 0.7570621468926554, 'accuracy': 0.9723294723294723}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/notebooks/../src/evaluation.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert OOD Results: {'precision': 0.7982456140350878, 'recall': 0.8198198198198198, 'f1': 0.8088888888888889, 'accuracy': 0.975072463768116}\n"
     ]
    }
   ],
   "source": [
    "# OOD\n",
    "OOD_results = {}\n",
    "importlib.reload(dataset)\n",
    "\n",
    "for model_key in [\"deberta\", \"modernbert\", \"bert\"]:\n",
    "    pairs = dataset.read_token_label_file(OOD_DATA)\n",
    "    sents_tok, sents_lab = dataset.group_into_sentences(pairs)\n",
    "    ds_full = dataset.build_hf_dataset_for_token_classification(sents_tok, sents_lab, model_key=model_key)\n",
    "    ds_full.save_to_disk(HF_DATA/f\"{model_key}\"/\"OOD\")\n",
    "\n",
    "# -- OOD evaluation loop:\n",
    "OOD_results = {}\n",
    "for model_key in [\"deberta\", \"modernbert\", \"bert\"]:\n",
    "    model_dir = paths.chekpoints / model_key\n",
    "    trainer = evaluation.load_trainer_for_eval(model_dir, HF_DATA / model_key / \"OOD\")\n",
    "    pred = trainer.predict(trainer.eval_dataset)  # use their own OOD eval set\n",
    "    logits = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    metrics = evaluation.compute_prf(logits, labels)\n",
    "    OOD_results[model_key] = metrics\n",
    "    print(f\"{model_key} OOD Results:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "473f6a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deberta</th>\n",
       "      <td>0.920792</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.988221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.819820</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>0.975072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modernbert</th>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.690722</td>\n",
       "      <td>0.757062</td>\n",
       "      <td>0.972329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            precision    recall        f1  accuracy\n",
       "deberta      0.920792  0.885714  0.902913  0.988221\n",
       "bert         0.798246  0.819820  0.808889  0.975072\n",
       "modernbert   0.837500  0.690722  0.757062  0.972329"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(OOD_results).T.sort_values(\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "954a72c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/notebooks/../src/evaluation.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁più ▁aff ▁\" ▁Feder ▁: ▁« ▁voi ▁a ▁una ▁bu ▁nu ▁da ▁dar ▁\" ▁e ▁me ▁la ▁fate ▁tanto ▁so ▁? ▁»▌ ▁« ▁Una ▁bu ▁nu ▁\" ▁io ▁?▌ ▁Ho ▁l ▁inferno ▁nel ▁cu ▁; ▁e ▁vi ▁dar ▁una ▁bu ▁nu ▁?▌ ▁Dit ▁voi ▁\" ▁se ▁lo ▁sap ▁\" ▁qual ▁è ▁quest ▁bu ▁nu ▁che ▁as ▁da ▁un ▁par ▁mio ▁. ▁»▌ ▁« ▁Che ▁Dio ▁v ▁ha ▁to ▁il ▁cu ▁\" ▁e ▁vu ▁far ▁suo ▁\" ▁» ▁ris ▁pa ▁il ▁cardinal ▁.▌ ▁« ▁Dio ▁! ▁Dio ▁! ▁Dio ▁!▌ ▁Se ▁lo ▁ved ▁!▌ ▁Se ▁lo ▁sent ▁!▌ ▁Dov ▁è ▁questo ▁Dio ▁? ▁»▌ ▁« ▁Voi ▁me ▁lo ▁do ▁? ▁voi ▁?▌ ▁E ▁chi ▁più ▁di ▁voi ▁l ▁ha ▁vic ▁?▌ ▁Non ▁ve ▁lo ▁sent ▁in ▁cu ▁\" ▁che ▁v ▁op ▁\" ▁che ▁v ▁a ▁\" ▁che ▁non ▁vi ▁las ▁stare ▁\" ▁e ▁n ▁st ▁tempo ▁v ▁at ▁\" ▁vi ▁fa ▁present ▁una ▁s ▁di ▁quiet ▁\" ▁di ▁cons ▁\" ▁d ▁una ▁cons ▁che ▁sar ▁pie ▁\" ▁i ▁\" ▁sub ▁che ▁voi ▁lo ▁rico ▁\" ▁lo ▁confess ▁\" ▁l ▁impl ▁? ▁»▌ ▁« ▁Oh ▁\" ▁cer ▁! ▁ho ▁qui ▁qual ▁cosa ▁che ▁m ▁op ▁\" ▁che ▁mi ▁rode ▁!▌ ▁Ma ▁Dio ▁!▌ ▁Se ▁c ▁è ▁questo ▁Dio ▁\" ▁se ▁è ▁quell ▁che ▁di ▁\" ▁cosa ▁vol ▁che ▁f ▁di ▁me ▁? ▁»▌ ▁Quest ▁parole ▁fur ▁de ▁con ▁un ▁accent ▁disp ▁; ▁ma ▁Feder ▁\" ▁con ▁un ▁to ▁sole ▁\" ▁come ▁di ▁placid ▁is ▁\" ▁ris ▁: ▁« ▁cosa ▁pu ▁far ▁Dio ▁di ▁voi ▁? ▁cosa ▁vu ▁far ▁?▌ ▁Un ▁seg ▁della ▁sua ▁pot ▁e ▁della ▁sua ▁bon ▁: ▁vu ▁ca ▁da ▁voi ▁una ▁glo ▁che ▁ness ▁al ▁gli ▁pot ▁dare ▁.▌ ▁Che ▁il ▁mondo ▁grid ▁da ▁tanto ▁tempo ▁contro ▁di ▁voi ▁\" ▁che ▁mill ▁e ▁mill ▁voc ▁detest ▁le ▁vos ▁op ▁. ▁» ▁( ▁l ▁in ▁si ▁sc ▁\" ▁e ▁rim ▁stu ▁un ▁momento ▁nel ▁sent ▁quel ▁lingua ▁cos ▁in ▁\"\n",
      "▁in ▁comp ▁\" ▁be ▁; ▁a ▁\" ▁tu ▁pu ▁be ▁dorm ▁una ▁not ▁in ▁terra ▁.▌ ▁Fall ▁cor ▁\" ▁ti ▁di ▁; ▁tie ▁all ▁.▌ ▁E ▁che ▁non ▁a ▁a ▁lament ▁di ▁te ▁! ▁»▌ ▁Co ▁det ▁\" ▁si ▁moss ▁rapid ▁verso ▁l ▁us ▁.▌ ▁Lucia ▁s ▁a ▁e ▁co ▁per ▁tra ▁\" ▁e ▁rin ▁la ▁sua ▁pre ▁; ▁ma ▁era ▁spa ▁.▌ ▁« ▁Oh ▁po ▁me ▁!▌ ▁Chi ▁\" ▁chi ▁sub ▁. ▁»▌ ▁E ▁sent ▁ch ▁ebb ▁acc ▁i ▁batten ▁e ▁sc ▁il ▁pal ▁\" ▁torn ▁a ▁ran ▁nel ▁suo ▁can ▁.▌ ▁« ▁Oh ▁po ▁me ▁! ▁» ▁es ▁di ▁nu ▁sing ▁: ▁« ▁chi ▁pre ▁or ▁?▌ ▁Dove ▁sono ▁?▌ ▁Dit ▁voi ▁\" ▁dit ▁per ▁car ▁\" ▁chi ▁è ▁quel ▁sign ▁. ▁quell ▁che ▁m ▁ha ▁par ▁? ▁»▌ ▁« ▁Chi ▁è ▁\" ▁eh ▁? ▁chi ▁è ▁?▌ ▁Vol ▁ch ▁io ▁ve ▁lo ▁di ▁.▌ ▁Asp ▁ch ▁io ▁te ▁lo ▁di ▁.▌ ▁Per ▁vi ▁prote ▁\" ▁a ▁mess ▁su ▁superb ▁; ▁e ▁vol ▁ ▁so ▁voi ▁\" ▁e ▁far ▁and ▁di ▁mezzo ▁me ▁.▌ ▁Do ▁a ▁lui ▁.▌ ▁S ▁io ▁vi ▁content ▁anche ▁in ▁questo ▁\" ▁non ▁mi ▁to ▁di ▁quell ▁bu ▁parole ▁che ▁a ▁sent ▁voi ▁. ▁»▌ ▁– ▁I ▁son ▁ve ▁\" ▁son ▁ve ▁\" ▁– ▁continu ▁\" ▁mor ▁tra ▁i ▁dent ▁.▌ ▁– ▁Male ▁le ▁gi ▁\" ▁che ▁fan ▁be ▁ve ▁a ▁pi ▁e ▁a ▁ride ▁\" ▁e ▁hanno ▁sempre ▁rag ▁. ▁– ▁Ma ▁sent ▁Lucia ▁sing ▁\" ▁e ▁torn ▁min ▁all ▁men ▁il ▁com ▁del ▁pad ▁\" ▁si ▁chin ▁verso ▁la ▁po ▁rin ▁\" ▁e ▁\" ▁con ▁voce ▁rad ▁\" ▁rip ▁: ▁« ▁via ▁\" ▁non ▁v ▁ho ▁det ▁n ▁di ▁male ▁: ▁state ▁all ▁.▌ ▁Non ▁mi ▁do ▁di ▁quell ▁co ▁che ▁non ▁vi ▁poss ▁dire ▁; ▁e ▁del ▁rest ▁\" ▁state ▁di ▁bu\n",
      "▁\" ▁e ▁in ▁più ▁minut ▁dai ▁pic ▁compar ▁delle ▁vet ▁.▌ ▁Un ▁qual ▁demon ▁\" ▁o ▁. ▁un ▁qual ▁angel ▁che ▁la ▁prote ▁. ▁.▌ ▁Compassion ▁al ▁Nib ▁! ▁.▌ ▁Do ▁\" ▁do ▁di ▁bu ▁or ▁\" ▁fu ▁di ▁qui ▁cost ▁; ▁al ▁suo ▁des ▁\" ▁e ▁non ▁se ▁ne ▁par ▁più ▁\" ▁e ▁\" ▁– ▁prose ▁tra ▁sé ▁\" ▁con ▁quell ▁an ▁con ▁cui ▁si ▁com ▁a ▁un ▁rag ▁in ▁\" ▁sap ▁che ▁non ▁u ▁\" ▁– ▁e ▁non ▁ci ▁si ▁pens ▁più ▁.▌ ▁Que ▁animal ▁di ▁don ▁Rodrigo ▁non ▁mi ▁v ▁a ▁romper ▁la ▁test ▁con ▁ring ▁; ▁che ▁. ▁non ▁v ▁più ▁sent ▁par ▁di ▁cost ▁.▌ ▁L ▁ho ▁servi ▁per ▁. ▁per ▁ho ▁prom ▁: ▁e ▁ho ▁prom ▁per ▁. ▁è ▁il ▁mio ▁des ▁.▌ ▁Ma ▁v ▁che ▁me ▁lo ▁p ▁be ▁questo ▁servi ▁\" ▁co ▁.▌ ▁Ved ▁un ▁poco ▁.▌ ▁–▌ ▁E ▁vol ▁almanac ▁cosa ▁a ▁pot ▁rich ▁di ▁scab ▁\" ▁per ▁comp ▁\" ▁e ▁quasi ▁per ▁pen ▁; ▁ma ▁gli ▁si ▁at ▁di ▁nu ▁all ▁men ▁quell ▁parole ▁: ▁compassion ▁al ▁Nib ▁!▌ ▁– ▁Come ▁pu ▁a ▁fat ▁cost ▁? ▁– ▁continua ▁\" ▁stra ▁da ▁quel ▁pens ▁.▌ ▁– ▁V ▁ved ▁.▌ ▁Eh ▁! ▁no ▁.▌ ▁S ▁\" ▁v ▁ved ▁. ▁–▌ ▁E ▁d ▁una ▁stanza ▁in ▁un ▁al ▁\" ▁t ▁una ▁scale ▁\" ▁e ▁su ▁a ▁ta ▁\" ▁and ▁all ▁camera ▁della ▁ve ▁\" ▁e ▁pic ▁all ▁us ▁con ▁un ▁calci ▁.▌ ▁« ▁Chi ▁è ▁? ▁»▌ ▁« ▁Apr ▁. ▁»▌ ▁A ▁quell ▁voce ▁\" ▁la ▁ve ▁f ▁tre ▁salt ▁; ▁e ▁sub ▁si ▁sent ▁sc ▁il ▁pal ▁negli ▁an ▁\" ▁e ▁l ▁us ▁si ▁spa ▁.▌ ▁L ▁in ▁\" ▁dalla ▁so ▁\" ▁died ▁un ▁ ▁in ▁g ▁; ▁e ▁\" ▁al ▁ ▁d ▁una ▁luc ▁che ▁a ▁sur ▁un ▁ta\n",
      "e ▁\" ▁et ▁m ▁pen ▁pec ▁et ▁an ▁corporal ▁sino ▁all ▁gal ▁\" ▁all ▁ ▁di ▁S ▁\" ▁second ▁la ▁qual ▁de ▁casi ▁et ▁delle ▁person ▁.▌ ▁Al ▁ris ▁b ▁era ▁gi ▁stato ▁f ▁il ▁prezzo ▁prima ▁della ▁so ▁; ▁come ▁prob ▁la ▁tariff ▁o ▁\" ▁per ▁us ▁quell ▁den ▁celeb ▁negli ▁an ▁modern ▁\" ▁il ▁maximum ▁del ▁gran ▁e ▁dell ▁alt ▁gran ▁più ▁or ▁sar ▁stato ▁f ▁con ▁alt ▁grid ▁\" ▁che ▁non ▁c ▁è ▁av ▁di ▁ve ▁.▌ ▁Man ▁cos ▁il ▁pane ▁e ▁la ▁far ▁a ▁bu ▁merc ▁in ▁Milano ▁\" ▁ne ▁veni ▁di ▁cons ▁che ▁dalla ▁camp ▁acc ▁gente ▁a ▁procession ▁a ▁comprar ▁.▌ ▁Don ▁Gonzalo ▁\" ▁per ▁rip ▁a ▁questo ▁\" ▁come ▁dice ▁lui ▁\" ▁inconvenient ▁\" ▁pro ▁\" ▁con ▁un ▁al ▁grid ▁del ▁15 ▁di ▁dic ▁\" ▁di ▁port ▁fu ▁della ▁cit ▁pane ▁\" ▁per ▁più ▁del ▁valor ▁di ▁vent ▁sold ▁; ▁pen ▁la ▁per ▁del ▁pane ▁me ▁\" ▁e ▁vent ▁sc ▁\" ▁et ▁in ▁caso ▁di ▁in ▁\" ▁di ▁due ▁tra ▁di ▁cord ▁in ▁public ▁\" ▁et ▁m ▁pen ▁an ▁\" ▁second ▁il ▁so ▁\" ▁all ▁ ▁di ▁S ▁Il ▁22 ▁dello ▁st ▁me ▁( ▁e ▁non ▁si ▁ve ▁per ▁cos ▁t ▁) ▁\" ▁pub ▁un ▁or ▁so ▁per ▁le ▁far ▁e ▁per ▁i ▁gran ▁.▌ ▁La ▁molt ▁a ▁vol ▁far ▁nas ▁l ▁ab ▁col ▁sac ▁e ▁con ▁l ▁in ▁; ▁il ▁govern ▁vol ▁man ▁con ▁la ▁gal ▁e ▁con ▁la ▁cord ▁.▌ ▁I ▁me ▁era ▁convenient ▁tra ▁loro ▁; ▁ma ▁cosa ▁a ▁a ▁fare ▁col ▁fine ▁\" ▁il ▁let ▁lo ▁ve ▁: ▁come ▁va ▁in ▁fat ▁ad ▁o ▁\" ▁lo ▁ved ▁a ▁moment ▁.▌ ▁ ▁poi ▁facile ▁anche ▁ve ▁\" ▁e ▁non ▁in ▁l ▁oss ▁come ▁tra ▁que ▁stran ▁pro\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 0 — 6 predicted sentences:\n",
      " • a cui dove tir il collo \" per il ban di dome \" e port ; per non bis mai and con le mani v da que sign .\n",
      " • Rac tutto l acc ; e ved che vi di \" su due pie \" di quell co che a no non ver in test \" a pens un an . »\n",
      " • Renzo ab molto vol questo pare ; Lucia l app ; e Agnes \" superb d a da \" lev \" a una a una \" le po best dalla st \" ri le loro gamb \" come se faces un m di fi \" le av e le st con uno spa \" e le cons in man a Renzo ; il qual \" date e rice parole di s \" us dalla parte dell or \" per non ved da rag \" che gli corre diet \" grid : lo spo ! lo spo ! Co \"\n",
      " • at i camp o \" come di col \" i lu \" se n and per vi \" fre \" ripen all sua dis \" e rum il disc da fare al do Azz . Las poi\n",
      " • pens al let \" come doves stare in via quell po best \" cos leg e ten per le za \" a capo all in gi \" nella man d un u il qual \" a da t passion \" accom col gest i pens che gli pass a tumult per la men . Ora st\n",
      " • il bra per colle \" or l a per dis \" or lo di in a \"\n",
      "\n",
      "Example 1 — 18 predicted sentences:\n",
      " • più aff \" Feder : « voi a una bu nu da dar \" e me la fate tanto so ? »\n",
      " • « Una bu nu \" io ?\n",
      " • Ho l inferno nel cu ; e vi dar una bu nu ?\n",
      " • Dit voi \" se lo sap \" qual è quest bu nu che as da un par mio . »\n",
      " • « Che Dio v ha to il cu \" e vu far suo \" » ris pa il cardinal .\n",
      " • « Dio ! Dio ! Dio !\n",
      " • Se lo ved !\n",
      " • Se lo sent !\n",
      " • Dov è questo Dio ? »\n",
      " • « Voi me lo do ? voi ?\n",
      " • E chi più di voi l ha vic ?\n",
      " • Non ve lo sent in cu \" che v op \" che v a \" che non vi las stare \" e n st tempo v at \" vi fa present una s di quiet \" di cons \" d una cons che sar pie \" i \" sub che voi lo rico \" lo confess \" l impl ? »\n",
      " • « Oh \" cer ! ho qui qual cosa che m op \" che mi rode !\n",
      " • Ma Dio !\n",
      " • Se c è questo Dio \" se è quell che di \" cosa vol che f di me ? »\n",
      " • Quest parole fur de con un accent disp ; ma Feder \" con un to sole \" come di placid is \" ris : « cosa pu far Dio di voi ? cosa vu far ?\n",
      " • Un seg della sua pot e della sua bon : vu ca da voi una glo che ness al gli pot dare .\n",
      " • Che il mondo grid da tanto tempo contro di voi \" che mill e mill voc detest le vos op . » ( l in si sc \" e rim stu un momento nel sent quel lingua cos in \"\n",
      "\n",
      "Example 2 — 18 predicted sentences:\n",
      " • i servi delle due part si sl all dif de loro pad .\n",
      " • Il combat era dis \" e per il numero \" e anche per Lod mi pi a scans i col \" e a disarm il ne \" che ad ; ma questo vol la mort di lui \" a ogni cost . Lod\n",
      " • a gi rice al bra sin una pug d un bravo \" e una s leg in una guan \" e il ne principal gli pi add per fin ; quando Cristo \" ved il suo pad ne est per \" and col pug add al sign . Quest\n",
      " • \" riv t la sua i contro di lui \" lo pass con la spa . A\n",
      " • quell vista \" Lod \" come fu di sé \" c la sua nel vent del fer \" il qual cad mori \" quasi a un punto col pov Cristo . I\n",
      " • bra del gent \" visto ch era fin \" si died all fug \" mal : quell di Lod \" tart e sf anche loro \" non essen più a chi dare \" e non vol trova imp nella gente \" che gi acc \" scan da al parte : e Lod si t solo \" con que due fun comp a pie \" in mezzo a una foll . «\n",
      " • Com è and ? –\n",
      " • uno . – Son\n",
      " • due . – Gli\n",
      " • ha fat un nel vent . – Chi è\n",
      " • stato a ? – Quel pre\n",
      " • . – Oh santa\n",
      " • Maria \" che s ! – Chi cerca\n",
      " • trova . – Una le\n",
      " • p tutte . – Ha fin\n",
      " • anche lui . – Che col\n",
      " • ! – Vu essere\n",
      " • una fac s . – E quell\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Example 0 — 6 predicted sentences\n",
      "\n",
      " • a cui dovevo tirare il collo \",\" per il banchetto di domenica \",\" e portateglieli ; perché non bisogna mai andar con le mani vòte da que' signori . Rac\n",
      " • contategli tutto l' accaduto ; e vedrete che vi dirà \",\" su due piedi \",\" di quelle cose che a noi non verrebbero in testa \",\" a pensarci un anno . » Renzo\n",
      " • abbracciò molto volentieri questo parere ; Lucia l' approvò ; e Agnese \",\" superba d' averlo dato \",\" levò \",\" a una a una \",\" le povere bestie dalla stìa \",\" riunì le loro otto gambe \",\" come se facesse un mazzetto di fiori \",\" le avvolse e le strinse con uno spago \",\" e le consegnò in mano a Renzo ; il quale \",\" date e ricevute parole di speranza \",\" uscì dalla parte dell' orto \",\" per non esser veduto da' ragazzi \",\" che gli correrebber dietro \",\" gridando : lo sposo ! lo sposo ! Co\n",
      " • sì \",\" attraversando i campi o \",\" come dicon colà \",\" i luoghi \",\" se n' andò per viottole \",\" fremendo \",\" ripensando alla sua disgrazia \",\" e ruminando il discorso da fare al dottor Azzecca-garbugli . Las\n",
      " • cio poi pensare al lettore \",\" come dovessero stare in viaggio quelle povere bestie \",\" così legate e tenute per le zampe \",\" a capo all' in giù \",\" nella mano d' un uomo il quale \",\" agitato da tante passioni \",\" accompagnava col gesto i pensieri che gli passavan a tumulto per la mente . Ora\n",
      " • stendeva il braccio per collera \",\" ora l' alzava per disperazione \",\" ora lo dibatteva in aria \",\"\n",
      "\n",
      "### Example 1 — 18 predicted sentences\n",
      "\n",
      " • più affettuosamente \",\" Federigo : « voi avete una buona nuova da darmi \",\" e me la fate tanto sospirare ? » «\n",
      " • Una buona nuova \",\" io ? Ho\n",
      " • l' inferno nel cuore ; e vi darò una buona nuova ? Dit\n",
      " • emi voi \",\" se lo sapete \",\" qual è questa buona nuova che aspettate da un par mio . » «\n",
      " • Che Dio v' ha toccato il cuore \",\" e vuol farvi suo \",\" » rispose pacatamente il cardinale . «\n",
      " • Dio ! Dio ! Dio ! Se\n",
      " • lo vedessi ! Se\n",
      " • lo sentissi ! Dov\n",
      " • ' è questo Dio ? » «\n",
      " • Voi me lo domandate ? voi ? E\n",
      " • chi più di voi l' ha vicino ? Non\n",
      " • ve lo sentite in cuore \",\" che v' opprime \",\" che v' agita \",\" che non vi lascia stare \",\" e nello stesso tempo v' attira \",\" vi fa presentire una speranza di quiete \",\" di consolazione \",\" d' una consolazione che sarà piena \",\" immensa \",\" subito che voi lo riconosciate \",\" lo confessiate \",\" l' imploriate ? » «\n",
      " • Oh \",\" certo ! ho qui qualche cosa che m' opprime \",\" che mi rode ! Ma\n",
      " • Dio ! Se\n",
      " • c' è questo Dio \",\" se è quello che dicono \",\" cosa volete che faccia di me ? » Quest\n",
      " • e parole furon dette con un accento disperato ; ma Federigo \",\" con un tono solenne \",\" come di placida ispirazione \",\" rispose : « cosa può far Dio di voi ? cosa vuol farne ? Un\n",
      " • segno della sua potenza e della sua bontà : vuol cavar da voi una gloria che nessun altro gli potrebbe dare . Che\n",
      " • il mondo gridi da tanto tempo contro di voi \",\" che mille e mille voci detestino le vostre opere ... » ( l' innominato si scosse \",\" e rimase stupefatto un momento nel sentir quel linguaggio così insolito \",\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Window 1\n",
      "P: più affettuosamente \",\" Federigo : « voi avete una buona nuova da darmi \",\" e me la fate tanto sospirare ? » « | Una buona nuova \",\" io ? Ho | l' inferno nel cuore ; e vi darò una buona nuova ? Dit | emi voi \",\" se lo sapete \",\" qual è questa buona nuova che aspettate da un par mio . » « | Che Dio v' ha toccato il cuore \",\" e vuol farvi suo \",\" » rispose pacatamente il cardinale . « | Dio ! Dio ! Dio ! Se | lo vedessi ! Se | lo sentissi ! Dov | ' è questo Dio ? » « | Voi me lo domandate ? voi ? E | chi più di voi l' ha vicino ? Non | ve lo sentite in cuore \",\" che v' opprime \",\" che v' agita \",\" che non vi lascia stare \",\" e nello stesso tempo v' attira \",\" vi fa presentire una speranza di quiete \",\" di consolazione \",\" d' una consolazione che sarà piena \",\" immensa \",\" subito che voi lo riconosciate \",\" lo confessiate \",\" l' imploriate ? » « | Oh \",\" certo ! ho qui qualche cosa che m' opprime \",\" che mi rode ! Ma | Dio ! Se | c' è questo Dio \",\" se è quello che dicono \",\" cosa volete che faccia di me ? » Quest | e parole furon dette con un accento disperato ; ma Federigo \",\" con un tono solenne \",\" come di placida ispirazione \",\" rispose : « cosa può far Dio di voi ? cosa vuol farne ? Un | segno della sua potenza e della sua bontà : vuol cavar da voi una gloria che nessun altro gli potrebbe dare . Che | il mondo gridi da tanto tempo contro di voi \",\" che mille e mille voci detestino le vostre opere ... » ( l' innominato si scosse \",\" e rimase stupefatto un momento nel sentir quel linguaggio così insolito \",\n",
      "G: più affettuosamente \",\" Federigo : « voi avete una buona nuova da darmi \",\" e me la fate tanto sospirare ? » « | Una buona nuova \",\" io ? Ho | l' inferno nel cuore ; e vi darò una buona nuova ? Dit | emi voi \",\" se lo sapete \",\" qual è questa buona nuova che aspettate da un par mio . » « | Che Dio v' ha toccato il cuore \",\" e vuol farvi suo \",\" » rispose pacatamente il cardinale . « | Dio ! Dio | ! Dio | ! Se | lo vedessi ! Se | lo sentissi ! Dov | ' è questo Dio ? » « | Voi me lo domandate ? voi ? E | chi più di voi l' ha vicino ? Non | ve lo sentite in cuore \",\" che v' opprime \",\" che v' agita \",\" che non vi lascia stare \",\" e nello stesso tempo v' attira \",\" vi fa presentire una speranza di quiete \",\" di consolazione \",\" d' una consolazione che sarà piena \",\" immensa \",\" subito che voi lo riconosciate \",\" lo confessiate \",\" l' imploriate ? » « | Oh \",\" certo ! ho qui qualche cosa che m' opprime \",\" che mi rode ! Ma | Dio ! Se | c' è questo Dio \",\" se è quello che dicono \",\" cosa volete che faccia di me ? » Quest | e parole furon dette con un accento disperato ; ma Federigo \",\" con un tono solenne \",\" come di placida ispirazione \",\" rispose : « cosa può far Dio di voi ? cosa vuol farne ? Un | segno della sua potenza e della sua bontà : vuol cavar da voi una gloria che nessun altro gli potrebbe dare . Che | il mondo gridi da tanto tempo contro di voi \",\" che mille e mille voci detestino le vostre opere ... » ( l' innominato si scosse \",\" e rimase stupefatto un momento nel sentir quel linguaggio così insolito \",\n",
      "\n",
      "### Window 6\n",
      "P: in compagnia \",\" bene ; altrimenti \",\" tu puoi ben dormire una notte in terra . Fall | e coraggio \",\" ti dico ; tienla allegra . E | che non abbia a lamentarsi di te ! » Co | sì detto \",\" si mosse rapidamente verso l' uscio . Lucia | s' alzò e corse per trattenerlo \",\" e rinnovare la sua preghiera ; ma era sparito . « | Oh povera me ! Chi | udete \",\" chiudete subito . » E | sentito ch' ebbe accostare i battenti e scorrere il paletto \",\" tornò a rannicchiarsi nel suo cantuccio . « | Oh povera me ! » esclamò di nuovo singhiozzando : « chi pregherò ora ? Dove | sono ? Dit | emi voi \",\" ditemi per carità \",\" chi è quel signore ... quello che m' ha parlato ? » « | Chi è \",\" eh ? chi è ? Vol | ete ch' io ve lo dica . Asp | etta ch' io te lo dica . Per | ché vi protegge \",\" avete messo su superbia ; e volete esser soddisfatta voi \",\" e farne andar di mezzo me . Do | mandatene a lui . S | ' io vi contentassi anche in questo \",\" non mi toccherebbe di quelle buone parole che avete sentite voi . » – | Io son vecchia \",\" son vecchia \",\" – continuò \",\" mormorando tra i denti . – | Maledette le giovani \",\" che fanno bel vedere a piangere e a ridere \",\" e hanno sempre ragione . – Ma sentendo Lucia singhiozzare \",\" e tornandole minaccioso alla mente il comando del padrone \",\" si chinò verso la povera rincantucciata \",\" e \",\" con voce raddolcita \",\" riprese : « via \",\" non v' ho detto niente di male : state allegra . Non | mi domandate di quelle cose che non vi posso dire ; e del resto \",\" state di buon\n",
      "G: in compagnia \",\" bene ; altrimenti \",\" tu puoi ben dormire una notte in terra . Fall | e coraggio \",\" ti dico ; tienla allegra . E | che non abbia a lamentarsi di te ! » Co | sì detto \",\" si mosse rapidamente verso l' uscio . Lucia | s' alzò e corse per trattenerlo \",\" e rinnovare la sua preghiera ; ma era sparito . « | Oh povera me ! Chi | udete \",\" chiudete subito . » E | sentito ch' ebbe accostare i battenti e scorrere il paletto \",\" tornò a rannicchiarsi nel suo cantuccio . « | Oh povera me ! » esclamò di nuovo singhiozzando : « chi pregherò ora ? Dove | sono ? Dit | emi voi \",\" ditemi per carità \",\" chi è quel signore ... quello che m' ha parlato ? » « | Chi è \",\" eh ? chi è ? Vol | ete ch' io ve lo dica . Asp | etta ch' io te lo dica . Per | ché vi protegge \",\" avete messo su superbia ; e volete esser soddisfatta voi \",\" e farne andar di mezzo me . Do | mandatene a lui . S | ' io vi contentassi anche in questo \",\" non mi toccherebbe di quelle buone parole che avete sentite voi . » – | Io son vecchia \",\" son vecchia \",\" – continuò \",\" mormorando tra i denti . – | Maledette le giovani \",\" che fanno bel vedere a piangere e a ridere \",\" e hanno sempre ragione . – Ma | sentendo Lucia singhiozzare \",\" e tornandole minaccioso alla mente il comando del padrone \",\" si chinò verso la povera rincantucciata \",\" e \",\" con voce raddolcita \",\" riprese : « via \",\" non v' ho detto niente di male : state allegra . Non | mi domandate di quelle cose che non vi posso dire ; e del resto \",\" state di buon\n",
      "\n",
      "### Window 35\n",
      "P: \",\" e intagliata più minutamente dai piccoli compartimenti delle vetriate . Un | qualche demonio \",\" o ... un qualche angelo che la protegge . . Compassion | e al Nibbio ! .. | . Domattina \",\" domattina di buon' ora \",\" fuor di qui costei ; al suo destino \",\" e non se ne parli più \",\" e \",\" – proseguiva tra sé \",\" con quell' animo con cui si comanda a un ragazzo indocile \",\" sapendo che non ubbidirà \",\" – e non ci si pensi più . Que | ll' animale di don Rodrigo non mi venga a romper la testa con ringraziamenti ; che ... non voglio più sentir parlar di costei . L | ' ho servito perché ... perché ho promesso : e ho promesso perché ... è il mio destino . Ma | voglio che me lo paghi bene questo servizio \",\" colui . Ved | iamo un poco .. | . – E | voleva almanaccare cosa avrebbe potuto richiedergli di scabroso \",\" per compenso \",\" e quasi per pena ; ma gli si attraversaron di nuovo alla mente quelle parole : compassione al Nibbio ! – | Come può aver fatto costei ? – continuava \",\" strascinato da quel pensiero . – | Voglio vederla .. | . Eh ! no .. | . Sì \",\" voglio vederla . – E | d' una stanza in un' altra \",\" trovò una scaletta \",\" e su a tastone \",\" andò alla camera della vecchia \",\" e picchiò all' uscio con un calcio . « | Chi è ? » « | Apri . » A | quella voce \",\" la vecchia fece tre salti ; e subito si sentì scorrere il paletto negli anelli \",\" e l' uscio si spalancò . L | ' innominato \",\" dalla soglia \",\" diede un' occhiata in giro ; e \",\" al lume d' una lucerna che ardeva sur un ta\n",
      "G: \",\" e intagliata più minutamente dai piccoli compartimenti delle vetriate . Un | qualche demonio \",\" o ... un qualche angelo che la protegge . . Compassion | e al Nibbio ! .. | . Domattina \",\" domattina di buon' ora \",\" fuor di qui costei ; al suo destino \",\" e non se ne parli più \",\" e \",\" – proseguiva tra sé \",\" con quell' animo con cui si comanda a un ragazzo indocile \",\" sapendo che non ubbidirà \",\" – e non ci si pensi più . Que | ll' animale di don Rodrigo non mi venga a romper la testa con ringraziamenti ; che ... non voglio più sentir parlar di costei . L | ' ho servito perché ... perché ho promesso : e ho promesso perché ... è il mio destino . Ma | voglio che me lo paghi bene questo servizio \",\" colui . Ved | iamo un poco ... – E | voleva almanaccare cosa avrebbe potuto richiedergli di scabroso \",\" per compenso \",\" e quasi per pena ; ma gli si attraversaron di nuovo alla mente quelle parole : compassione al Nibbio ! – | Come può aver fatto costei ? – continuava \",\" strascinato da quel pensiero . – | Voglio vederla .. | . Eh ! no .. | . Sì \",\" voglio vederla . – E | d' una stanza in un' altra \",\" trovò una scaletta \",\" e su a tastone \",\" andò alla camera della vecchia \",\" e picchiò all' uscio con un calcio . « | Chi è ? » « | Apri . » A | quella voce \",\" la vecchia fece tre salti ; e subito si sentì scorrere il paletto negli anelli \",\" e l' uscio si spalancò . L | ' innominato \",\" dalla soglia \",\" diede un' occhiata in giro ; e \",\" al lume d' una lucerna che ardeva sur un ta\n",
      "\n",
      "### Window 48\n",
      "P: e \",\" et maggior pena pecuniaria et ancora corporale sino alla galera \",\" all' arbitrio di S.E. \",\" secondo la qualità de' casi et delle persone . Al | riso brillato era già stato fissato il prezzo prima della sommossa ; come probabilmente la tariffa o \",\" per usare quella denominazione celeberrima negli annali moderni \",\" il maximum del grano e dell' altre granaglie più ordinarie sarà stato fissato con altre gride \",\" che non c' è avvenuto di vedere . Man | tenuto così il pane e la farina a buon mercato in Milano \",\" ne veniva di conseguenza che dalla campagna accorresse gente a processione a comprarne . Don | Gonzalo \",\" per riparare a questo \",\" come dice lui \",\" inconveniente \",\" proibì \",\" con un' altra grida del 15 di dicembre \",\" di portar fuori della città pane \",\" per più del valore di venti soldi ; pena la perdita del pane medesimo \",\" e venticinque scudi \",\" et in caso di inhabilità \",\" di due tratti di corda in publico \",\" et maggior pena ancora \",\" secondo il solito \",\" all' arbitrio di S.E. Il 22 dello stesso mese ( e non si vede perché così tardi ) \",\" pubblicò un ordine somigliante per le farine e per i grani . La | moltitudine aveva voluto far nascere l' abbondanza col saccheggio e con l' incendio ; il governo voleva mantenerla con la galera e con la corda . I | mezzi erano convenienti tra loro ; ma cosa avessero a fare col fine \",\" il lettore lo vede : come valessero in fatto ad ottenerlo \",\" lo vedrà a momenti . | È poi facile anche vedere \",\" e non inutile l' osservare come tra quegli strani provvedimenti\n",
      "G: e \",\" et maggior pena pecuniaria et ancora corporale sino alla galera \",\" all' arbitrio di S.E. \",\" secondo la qualità de' casi et delle persone . Al | riso brillato era già stato fissato il prezzo prima della sommossa ; come probabilmente la tariffa o \",\" per usare quella denominazione celeberrima negli annali moderni \",\" il maximum del grano e dell' altre granaglie più ordinarie sarà stato fissato con altre gride \",\" che non c' è avvenuto di vedere . Man | tenuto così il pane e la farina a buon mercato in Milano \",\" ne veniva di conseguenza che dalla campagna accorresse gente a processione a comprarne . Don | Gonzalo \",\" per riparare a questo \",\" come dice lui \",\" inconveniente \",\" proibì \",\" con un' altra grida del 15 di dicembre \",\" di portar fuori della città pane \",\" per più del valore di venti soldi ; pena la perdita del pane medesimo \",\" e venticinque scudi \",\" et in caso di inhabilità \",\" di due tratti di corda in publico \",\" et maggior pena ancora \",\" secondo il solito \",\" all' arbitrio di S. | E. Il 22 dello stesso mese ( e non si vede perché così tardi ) \",\" pubblicò un ordine somigliante per le farine e per i grani . La | moltitudine aveva voluto far nascere l' abbondanza col saccheggio e con l' incendio ; il governo voleva mantenerla con la galera e con la corda . I | mezzi erano convenienti tra loro ; ma cosa avessero a fare col fine \",\" il lettore lo vede : come valessero in fatto ad ottenerlo \",\" lo vedrà a momenti . | È poi facile anche vedere \",\" e non inutile l' osservare come tra quegli strani provvedimenti\n"
     ]
    }
   ],
   "source": [
    "best_key = max(OOD_results, key=lambda k: OOD_results[k][\"f1\"])\n",
    "model_dir = paths.chekpoints/best_key\n",
    "\n",
    "OOD_best_trainer = evaluation.load_trainer_for_eval(model_dir, HF_DATA / best_key / \"OOD\")\n",
    "OOD_ds = load_from_disk(HF_DATA/best_key/\"val\")\n",
    "results = error_examples(OOD_best_trainer, OOD_ds, max_show=5)\n",
    "\n",
    "evaluation.preview_predictions(OOD_best_trainer, OOD_ds, k=3)\n",
    "evaluation.preview_full_sentences(OOD_best_trainer, OOD_ds, n_examples=2)\n",
    "evaluation.preview_pred_vs_gold(OOD_best_trainer, OOD_ds, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed9c0bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/notebooks/../src/evaluation.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[deberta] saved VAL predictions: {'n_samples': 60, 'n_rows': 17305, 'word_only': True, 'path': '/home/user/mnlp/notebooks/../results/deberta_val_tokens.csv'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/notebooks/../src/evaluation.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[deberta] saved OOD predictions: {'n_samples': 6, 'n_rows': 1698, 'word_only': True, 'path': '/home/user/mnlp/notebooks/../results/deberta_OOD_tokens.csv'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/notebooks/../src/evaluation.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modernbert] saved VAL predictions: {'n_samples': 14, 'n_rows': 16499, 'word_only': True, 'path': '/home/user/mnlp/notebooks/../results/modernbert_val_tokens.csv'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/notebooks/../src/evaluation.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modernbert] saved OOD predictions: {'n_samples': 2, 'n_rows': 1554, 'word_only': True, 'path': '/home/user/mnlp/notebooks/../results/modernbert_OOD_tokens.csv'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/notebooks/../src/evaluation.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bert] saved VAL predictions: {'n_samples': 53, 'n_rows': 17274, 'word_only': True, 'path': '/home/user/mnlp/notebooks/../results/bert_val_tokens.csv'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mnlp/notebooks/../src/evaluation.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bert] saved OOD predictions: {'n_samples': 6, 'n_rows': 1725, 'word_only': True, 'path': '/home/user/mnlp/notebooks/../results/bert_OOD_tokens.csv'}\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import evaluation\n",
    "from datasets import load_from_disk\n",
    "\n",
    "importlib.reload(evaluation)\n",
    "\n",
    "model_keys = [\"deberta\", \"modernbert\", \"bert\"]\n",
    "\n",
    "for model_key in model_keys:\n",
    "    model_dir = paths.chekpoints / model_key\n",
    "\n",
    "    # --- Validation ---\n",
    "    val_ds_path = HF_DATA / model_key / \"val\"\n",
    "    val_ds = load_from_disk(val_ds_path)\n",
    "    val_tr = evaluation.load_trainer_for_eval(model_dir, val_ds_path)\n",
    "    val_out = paths.results / f\"{model_key}_val_tokens.csv\"   # or .parquet / .jsonl\n",
    "    _, val_summary = evaluation.save_token_predictions(val_tr, val_ds, val_out, word_only=True)\n",
    "    print(f\"[{model_key}] saved VAL predictions:\", val_summary)\n",
    "\n",
    "    # --- OOD ---\n",
    "    OOD_ds_path = HF_DATA / model_key / \"OOD\"\n",
    "    OOD_ds = load_from_disk(OOD_ds_path)\n",
    "    OOD_tr = evaluation.load_trainer_for_eval(model_dir, OOD_ds_path)\n",
    "    OOD_out = paths.results / f\"{model_key}_OOD_tokens.csv\"   # or .parquet / .jsonl\n",
    "    _, OOD_summary = evaluation.save_token_predictions(OOD_tr, OOD_ds, OOD_out, word_only=True)\n",
    "    print(f\"[{model_key}] saved OOD predictions:\", OOD_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
